#+hugo_base_dir: ../
#+STARTUP: logdone overview

* DONE 22 years of Emacs :@writing:emacs:
CLOSED: [2021-12-07 Tue]
:PROPERTIES:
:EXPORT_FILE_NAME: 22-years-of-emacs
:SUBTITLE: How a piece of advice became a lifestyle
:END:


** Where to begin...

I just watched David Wilson's talk called [[https://emacsconf.org/2021/talks/forever/][M-x forever - why Emacs will outlast text editor trends]]. He gave this talk at [[https://emacsconf.org/][EmacsConf 2021]] which is a conference dedicated to Emacs. The talk made me reflect on my use of Emacs over the last years and then I realized that this year will mark 22 years that Emacs and I have been together. This (probably too long) article reflects on those years and dives into my use of Emacs.

*** First Contact

Back in 1998 I was planning a move to the US. I had just finished my first professional programming gig writing a RAS Dialer for [[https://archive.org/details/FREELER][Freeler]] internet, the first "free" internet provider in The Netherlands. Pretty much everyone in The Netherlands (who had a modem and tried Freeler) was using my software to connect to the service. I was programming in various languages at the time, from Delphi (for the dialer) to Perl (yes, it was popular then!). This is when I first started playing with Linux and editors like Vi and Emacs.

When I moved to the US (San Francisco) I started working for [[https://blog.stevekrause.org/2005/09/personify-retrospective.html][Personify]], a company focused on building an analytical platform for e-commerce sites. I started working in a small team which dealt with webserver logfile parsing. That sounds like a great job for Perl, right? My mentor worked in the same team and he guided me through the hectic time of working at a pre-2000 startup in Silicon Valley.

*** Picking Emacs for life

As I was working closely with my mentor I started picking up on things he did. He was (and probably still is) a wizard behind the keyboard. He used Emacs as his editor. Naturally I gave it a try, but found it hard to really get productive with it and so I kept switching back and forth between Vi, Emacs and several other editors. It always amazed me how quick he was in getting stuff done. One day, my mentor told me to stop and /take the time to learn my tools/.

His reasoning was that when you learn your tool well it will not impede you from completing your task. You will be able to complete it as fast as you can simply because the tool becomes an extension of your thought process and it is possible to leverage the features it has to the benefit of the task at hand. It did not matter which tool I would choose, but pick one and learn it well. I accepted the challenge of working with a single tool for 30 days and see if my work speed would improve.

I chose to use Emacs, as it allowed me to look at the things he did. The availability of information on how to best use software was not as abundant as it is now. Now you can look up anything on YouTube or any blog, back then there was the Emacs Manual and other users that I ran into during technical meetups.

Now we are 22 years later and I still use Emacs everyday for pretty much anything. It has been with me through transitioning from Windows, to macOS and since 2017 full time on Linux. It came with me when moving between continents (back to Europe) and through various jobs at different companies.

*** Cheating on Emacs

I too have been tempted by new fashioned shiny tools that promised to be the next big thing in Editing. I even switched to Vim for a little while. The thing is, I always came back to Emacs. I think this is mostly due to the fact that new tools have something spectacular and then you want to adjust it and you find you can not do it to the degree that Emacs allows you to change the way it works for you.

While working with programming languages like Java the lure of IDEs has been quite tempting as well. In teams where pretty much everyone uses IntelliJ IDEA you stand out when just opening up Emacs. It often results in quite some interesting discussions as to what "makes a good developer". Some people are quite unreasonable and think an IDE makes the developer, but I greatly disagree on that topic.

*** Serendipity

Over the years there have been several serendipitous moments in the Emacs community for me. I will pick out 2:

- I started sponsoring [[https://github.com/tarsius][Jonas Bernoulli]] in 2021 for his work on [[https://github.com/magit/magit][Magit]] and back in 2012 he sent in a patch for my worklog package which I only found out while preparing this article and looking at the logs of my various projects.
- I was referenced [[https://youtu.be/DdkwNTgtIJ0?t=2429][in a talk by Martin Clausen]]. He gave a presentation on a Clojure project and in the conclusion he talked about knowing your tools. We had been doing some live streams together working on Clojure projects and while he talked about using your tools effectively he casually dropped a "then you need to talk to this guy" and pointed my out in the crowd.

** Giving back

*** A YouTube series

In 2015/2016 I started working a little less and found time to do a Friday morning live-coding series. It featured me learning to write Clojure by building various projects. In the videos I, of course, used Emacs in pretty much every way possible.

I also created a series of videos called [[https://www.youtube.com/watch?v=T1WBsI3gdDE&list=PLdKXxqwRv6_y7rHHjbrK38E59t9ost3o3][Productive Emacs]] in which I highlighted useful packages (focused on Clojure development). They were a big hit (at least I think so) and connected me to wonderful people like [[https://www.youtube.com/user/mzamansky][Mike Zamansky]].

*** Writing packages

In my time with Emacs I have written and maintained some code as well. Most notably in 2003 I took over a package for tracking time ([[https://github.com/credmp/worklog][worklog]]) as I had a job where I need to track my time and naturally I chose to do this in Emacs.

I also have a [[https://github.com/credmp/arjen-grey-theme/][grey theme]] out on [[https://melpa.org/#/arjen-grey-theme][melpa]] that is being used by several people. I always enjoy getting responses from the community when they like the work that has gone into making things.

Whenever I can I will post about some snippet of emacs-lisp I have written, such as my Advent of Code [[../../../posts/2021-11-13-Advent-of-Code-Helper/][helper function]]. It retrieves the input for a puzzle during December and puts it into a file. It then prints the puzzle description and allows you to quickly get going. It is awesome to use your editor to make your life easier!

*** Providing patches

One of the most meaningful things in this entire ecosystem is to give back to the projects when you can. Whenever I run into a bug or oddity I will try and fix it. When my skill-set allows it I will send in a patch or documentation update to show my appreciation for the work people do. This entire community runs on people spending their free time working on code that helps many of us.

** My configuration

Recently there was a twitter exchange with [[https://twitter.com/bbatsov/status/1463429044993769477][Bozhidat Batsov]] in which [[https://twitter.com/stephenaramsey][Stephen A. Ramsey]] calls Emacs a lifestyle choice as someone makes the remark that the people they know have been configuring Emacs as long as they have been using it.

[[./images/twitter.png]]

I too am one of those that is always tinkering with my configuration. I think it is part of having such an extensible editor and using it constantly for everything. The community keeps making amazing packages that provide entire new dimensions to the use of Emacs (hi use-package, Projectile, Counsel, Ivy, Org-Roam, Company, and many many more) that it only makes sense to be critical and try out anything that seems useful and an improvement. The ease with which it is possible to add new functions to Emacs is amazing.

I said ease, but for new users it can be quite daunting to start with a configuration. That is why projects like [[https://github.com/hlissner/doom-emacs][Doom Emacs]] and [[https://www.spacemacs.org/][Spacemacs]] are so important. I have tried both and I think the work done in them is amazing! I often go into their repositories and check out the packages they use and take snippets from their configuration.

A few years back I converted my pre-2000 ~init.el~ to a literal configuration using ~org-mode~ and ~babel~. This allows you to treat your configuration as documentation and annotate it using the wonderful ~org-mode~. Sadly I sometimes lack the discipline to properly annotate my configuration like [[https://protesilaos.com/][Protesilaos]] does.

You can still check out [[https://gitlab.com/buildfunthings/emacs-config][my configuration]] in its repository. The wonderful thing of having a configuration in the open is that many people take from it. It has resulted in various connections around the globe that to this day exchange ideas and experiments using my configuration as a base.

** Favorite packages

So after all these years, there must be some favorite packages. Yes there are. It is important to note that I use Emacs for pretty much everything in my day-to-day live; from making presentations and documents in LaTeX, keeping notes and scheduling in org-mode, writing code in languages such as Java, C, Rust and Clojure and reading my Email. The list below is in no means a complete reference, but it gives a sense of what I do in my day-to-day life using Emacs.

*** Org-mode and Org-Roam

I think [[https://orgmode.org/][org mode]] can be seen as one of the most influential packages in the Emacs ecosystem. For me it has taken over most of my note-taking, document processing needs.

Lets start with my daily tasks. As a teacher I have many daily things to keep track of, from work that needs reviewing, classes that need preparing and the grading of papers. To keep track of everything and not loose sight of anything I have implemented a [[https://gettingthingsdone.com/][Getting Things Done (GTD)]] workflow.

Anything that lives in a browser is connected to my GTD system using [[https://orgmode.org/worg/org-contrib/org-protocol.html][org-protocol]], anything that lives in Emacs is captured using [[https://orgmode.org/manual/Capture-templates.html][capture templates]]. This means that anything that will take me more then 2 minutes to take care of will go into my GTD system and will be filed away with scheduling dates, deadlines and notes on the task itself. In my archive I have cleared over 10000 tasks in the current version of the system.

The article you are reading now is also an Org document. It lives in an archive called website and has an Emacs build script that generates this website in a Github Action.

As an extension to org-mode I use [[https://www.orgroam.com/][org-roam]] to keep track of knowledge snippets. This can be anything from development tricks, hacking methodology, background information on some technology to grading notes on papers. All this knowledge is captured in my org-mode archive and is accessible through a series of links in topic covering notes.

[[./images/org-mode.png]]

*** Mu4e

The use of org-mode continues into my Email. All my mail is read through [[https://www.djcbsoftware.nl/code/mu/][mu4e]]. It seamlessly ties into my GTD workflow, its editing builds on the document processing I already do with org-mode and using various modules I can even read horrible HTML emails.

Most importantly, captures I have made from email into the GTD system will link directly to the email itself, so it is as if the system is one concise whole, making it very productive.

*** Magit

As I put everything I find of value into git repositories I tend to use [[https://magit.vc/][Magit]] quite a lot during the day. It has totally redefined how Emacs should do interfaces for tools and has shown the world how a good git interface can integrate into the editor. It puts anything else to shame in my opinion.

[[./images/magit.png]]

*** Which-Key

A few years back I added [[https://github.com/justbur/emacs-which-key][which-key]] to my configuration after reading an article on discoverability of features. It is an amazing extension that allows you to press a key combination and it will pop-up a list of all following combinations that can be accessed from there. This greatly helps when you are trying to remember that one key sequence for that feature you don't use that often.

[[./images/which-key.png]]

*** LSP / eglot

With the introduction of VSCode to the world Microsoft actually made something useful as well, the Language Server Protocol (LSP). The LSP is the thing that makes VSCode such a hit, it separated the editor frontend from the language understanding backend.

Emacs now has 2 LSP infrastructures, [[https://emacs-lsp.github.io/lsp-mode/][lsp-mode]] and [[https://github.com/joaotavora/eglot][eglot]]. I have tried both and eventually settled on using eglot for my daily programming tasks.

The lsp-mode package is the most extensive and feature loaded of the two, it also means it has a lot of configuration to tweak it to your liking. The package also takes care of installing the needed language server for your language and sets it up automatically.

On the other hand, eglot, is bare bones and configuration-less. Just drop it in and it works after manually installing a language server. It is simple and unobtrusive, and as I do a lot of screen sharing while coding I chose it over lsp-mode.

Both packages give Emacs an IDE set of features, such as context sensitive completion, formatting of code, refactoring, organization of imports and the execution of code actions on errors and warnings. It has redefined Emacs for me when it comes to writing code.

[[./images/lsp.png]]

*** Projectile

The last of my favorite packages is [[https://projectile.mx/][projectile]]. As the name implies it is a tool to work with projects. As I said, I maintain a lot git repositories for anything I deem of importance. Projectile interacts with these git projects and allows you to quickly open files in the project, search them, run commands on them, switch between test and implementation code and so on.

As a productivity tool projectile makes code editing that extra bit enjoyable.


** Helpful resources

As the community is large there are several resources I keep track of to find new features, applications and packages.


- [[https://masteringemacs.org/][Mastering Emacs]] :: a book and website with cool and useful tricks in Emacs.
- [[https://sachachua.com/blog/category/emacs-news/][Emacs News by Sacha Chua]] :: a weekly digest that summarizes the week of Emacs news, a great resource to read with a cup of coffee.
- [[https://www.reddit.com/r/emacs/][Emacs Reddit]] :: the Emacs sub-reddit is extremely wonderful when it comes to sharing information. The community is great and supportive (who would say this about Reddit, right?)
- YouTube :: the following channels offer a lot of information; [[https://www.youtube.com/c/ProtesilaosStavrou][Protesilaos]] and [[https://www.youtube.com/c/SystemCrafters][System Crafters]].

** Closing thoughts

Emacs and I have been together for 22 years now and I don't see it changing anytime soon. Emacs itself is getting better and better with initiatives such as [[https://www.emacswiki.org/emacs/GccEmacs][native-compilation]] and the Pure GTK patches. Its package ecosystem is in excellent condition and packages such as ~org-mode~ and ~eglot~ / ~lsp-mode~ make even the most demanding programming languages a joy to work with in Emacs.

Here's to another 22 years Emacs!

* DONE Deployment Anxiety :development:@writing:
CLOSED: [2022-11-16 Wed]
:PROPERTIES:
:EXPORT_FILE_NAME: deployment-anxiety
:END:

Let me tell you how it was to ship a product out to half a million people back in 1999. But before I do that, let me tell you why. Today I talked to one of my students and he mentioned that he was very nervous about a change he was making. He was afraid it would break things and that he would spend the afternoon working through his CI/CD pipeline to resolve issues.

Well, back in 1999 I worked on a project. Together with some friends we were building cool software in Borland Delphi and life was good. One of the things that we had built was a nifty dialler application that you could run on Windows. It would dial into your ISP and it made the entire process a lot easier and it made all the dealings with modems and telephone lines so much simpler. Why would we make such a thing? It was actually a commission for one of the earlier internet providers in The Netherlands. It was well received and  we made our first big bucks. It was awesome.

After finishing the project I received a call. There was a secret project in the parent company and they needed the software as well. The project turned out to be the creation of a /free/ internet provider.  The provider was Freeler. The term /free/ meant you only paid for your telephone line, but not for the service itself. It was a cool and radical idea and the parent company gave the project group 1 month to put everything into place and market it. In modern times that would be 1 sprint.

Needless to say it was a pressure cooker. In hindsight I did not really understand many of things going on, I was just focused on modifying my dialler application to do the job that was asked.  The idea was to have a CD ROM ready just before launch time. The CD ROM would then be placed at gas stations and other high traffic areas.  It had to work flawlessly. The thing with CD ROMs is that you /can't send a patch/ if something is wrong.

As I was just out of my teen years it was all quite hectic and I had never released software on this scale. So I made my changes to the application, but how do you make sure it is correct? It worked on my computer, but how do you test something like this? Well, first you need to make your CD ROM. So we built an image and sent it to the pressing company, we received a box a /few hundred testers the next day/. So, time to call all our family members? Fun fact, thanks to  people of the internet archive you can still download the CD ROM image [[https://archive.org/details/FREELER][from them]].

#+ATTR_HTML: :alt the Freeler CD ROM
#+ATTR_HTML: :width 300
[[./images/freeler.png]]


After some calls and research my technical partner on the project found a laboratory that actually specialized in testing CD ROMs. It was one of the coolest things ever; they take your CD ROM and feed it to a robotized setup. In this laboratory they had hundreds of machines from various manufacturers running various versions of the Windows operating system. It was pure magic to behold.

We spent several days at the laboratory getting results. Some machines did not auto start the software, others ran into issues setting up the connections. It was an effort, but at the end of the day I fixed all the issues and a /master cd/ was made. This is basically the template from which all the copies are created.

So, now we have some tested software and a distribution medium that will work with the target audience. We are finished right? Well, no. As people use the CD ROMs they will have questions. Some people will never have dialled into the internet before, some people might not even have a modem (no, that is not a joke). So to ensure their questions are answered a call center is needed. I don't remember how big the call center was, but I do remember it was in the center of Groningen.

Given the time crunch, the deadline was only in a few days, these operators needed to be trained. They needed to be trained in working with the dialler application. So I was sent to Groningen to work with the call center. Imagine the sight; you just created an application, went to a laboratory to test it, then created a bunch (a million-ish) CD ROMs and then you wait for people to call with issues. The first time the phone rings you heart drops. "Did it not work?", "Did I miss something?".... it is not like you can go around people's house to fix the issues. Patching it is not possible, since they use the application to get onto the internet.

Luckily for me the software worked quite nicely. Freeler grew to 350.000 members. But to release this simple piece of software I spent weeks working through many painstaking processes.

So why do I tell this story? Well... having the luxury of CI/CD, instant feedback and /the ability to patch things the same minute/hour/day should be the greatest good in the world/. Be fearless, merge your changes, fix your issues, deploy without anxiety.... you will never have to see a robot feed a CD ROM to a computer in order to find out if you code works.

* DONE Cleaning up after LSP-mode
CLOSED: [2022-11-07 Mon]
:PROPERTIES:
:EXPORT_FILE_NAME: cleaning-up-lsp-mode
:END:

I use [[https://emacs-lsp.github.io/lsp-mode/][lsp-mode]] quite extensively. I switched from eglot when I started using LSP more. The beautify of lsp-mode is that it will automatically install language servers as you need them. It also integrates excellently with [[https://emacs-lsp.github.io/dap-mode/][dap-mode]] to enable debugging sessions. So, I switched to it, turned off all the information overload and I am quite happy.

One thing I do extensively is that I use LaTeX to make my slides for college class slides and class assignments. That means I have hundreds of directories with presentations, assignments and other documents. Each time I enter a directory for a class it will spawn an LSP session for that set of LaTeX files.

Then there are the assignments that are handed in. Mostly Java and JavaScript types of projects that I grade. This is wonderful work and I am glad I can do it within Emacs, instead of having to spawn up some IDE to just browse code structures.

The downside to all this is that my ~lsp-describe-session~ list becomes huge. At one point I had over 100 sessions stored in it, most of them fleeting due to work I graded at the end of a semester. Luckily you can just clean those folders up by calling ~lsp-workspace-folders-remove~. As an interactive function you can call it, select the folder to remove and be done with it.

Needless to say that I did not feel like doing that manually for 100+ folders. So I created a small snippet of elisp to automate this. It is listed below, feel free to copy it. It will clean out *all* your LSP folders, so you will need to create the ones you need again after using it, but ~lsp-mode~ will do just that for you.

#+begin_src emacs-lisp
(defun aw/cleanup-lsp ()
  "Remove all the workspace folders from LSP"
  (interactive)
  (let ((folders (lsp-session-folders (lsp-session))))
    (while folders
      (lsp-workspace-folders-remove (car folders))
      (setq folders (cdr folders)))))
#+end_src
* DONE Should we pay for open source?
CLOSED: [2022-11-06 Sun]
:PROPERTIES:
:EXPORT_FILE_NAME: should-we-pay-for-oss
:END:

As the world is processing the [[https://www.forbes.com/sites/petersuciu/2022/11/05/twitter-is-facing-a-great-exodus--can-the-company-remain-profitable-if-it-loses-its-power-users/?sh=3a3aaec0212a][Twitter deal]] the open source project [[https://joinmastodon.org/][Mastodon]] is gaining a lot of traction. The instance that I am on, [[https://fostodon.org][fosstodon]], is run by a small team and is fully funded by [[https://hub.fosstodon.org/support/][donations]].

Now this may sound somewhat strange; as the twitterverse is blowing up about $8/month for a blue checkmark I would argue that the $8 is better spent supporting open source projects. As developers, security people, and users we rely on a lot of free time and effort from open source contributors.

** Sustainable open source

This idea of sustainable open source is not new. On Github you can already donate to your favorite projects and many people accept money through patreon or [[https://liberapay.com/][Liberapay]]. This is a good step towards sustainability. To illustrate what could go wrong if we don't move more into this direction we should look at the case of Marak Squiress.

You might've heard about ~color.js~ and ~faker.js~. The latter was used to generate fake data for testing forms in web applications and such. Both projects were used by thousands of other projects. Most developers did not even notice this dependency in their project as it would be deep into the dependency tree.

One day Marak got fed up. He was tired of working on his projects and seeing companies use his projects without giving back. So he pleaded with the outside world to no avail. Sadly it seems he totally burned out and removed his projects from various repositories. Needless to say, stuff started to break. As the NPM ecosystem is not geared towards reproducability (and general usability) a missing package will only be followed with absolute failure.

The [[https://www.bleepingcomputer.com/news/security/dev-corrupts-npm-libs-colors-and-faker-breaking-thousands-of-apps/][detailed story]] of Marak and his decision is quite the read, I highly recommend going through it and reflecting on what it would mean for your own projects.

** Dependencies

The fragility of dependencies is not new. In an XKCD comic it was beautifully illustrated:

[[./images/dependency.png]]

There are countless examples where this goes wrong. Just in the NPM space it is quite easy to find examples where funding would've helped. Lets take a look at some supply chain attacks where a better funded developer might've taken the time to actually setup better security for themselves.

In November of 2018 a malicious package was added as a dependency to version 3.3.6 of the popular package event-stream by a new maintainer. The malicious package, called flatmap-stream, contained an encrypted payload that stole bitcoins from certain applications. Read the [[https://blog.npmjs.org/post/180565383195/details-about-the-event-stream-incident][NPM Blog]] for an incident report.

In October of 2021 the NPM account for the UA-Parser-JS library was hijacked, to infect dependent systems with cryptominers and password-stealing trojans in a supply-chain attack. There is a [[https://www.bleepingcomputer.com/news/security/popular-npm-library-hijacked-to-install-password-stealers-miners/][Detailed story]] that goes into all the steps involved.

In July of 2018 the credentials of a maintainer on NPM were compromised resulting in a malicious release of eslint-scope, version 3.7.2. The malicious code copied the npm credentials of the machine running eslint-scope and uploaded them to the attacker. There is a good [[https://eslint.org/blog/2018/07/postmortem-for-malicious-package-publishes/][blog post]] by the ESLint team.

Although better funding does not mean better security posture, it would mean that developers get more time to spend on their projects. More time generally results in better choices and hopefully also security choices.

** OpenSSL

Outside the NPM realm you can also throw a stone and find an interesting story. Lets take a look at OpenSSL on November 1st of 2022. The release a critical patch for a vulnerability. Instead of it being something that was broken when security was not on the forefront this time it was a vulnerability in /new/ code. Code that was just recently added, knowing how important OpenSSL is in the ecosystem. Sadly it was not tested enough. The code dealt with the parsing of punycode urls in email addresses. It resulted in a trivial buffer overflow; using ~<=~ instead of ~<~. Read more about it in their [[https://www.openssl.org/blog/blog/2022/11/01/email-address-overflows/][blog post]].

** Closing thought

So, lets start working towards a sustainable open source culture where developers can get (well) paid for their work.

** After the post

After posting this earlier today the news dropped on hackernews that the author of [[https://github.com/rui314/mold][mold]], [[https://twitter.com/rui314][Rui Ueyama]], is thinking about changing the license for mold/macOS due to its lack of funding. His [[https://twitter.com/rui314/status/1589228847903698945][twitter post]] is unrolled below.

#+begin_quote
I was optimistic when I started the mold project that I'd be able to earn a comfortable income in some way if it becomes popular. But I may have to admit that that's a bit too optimistic. I'm still losing my money after two years.

I *have* enough money that I earned when I was working as a full-time software engineer, but if I keep losing money, it's not sustainable long term.
It's even a bit ironic that I had been asked by several big-name companies when mold/macOS would become available, since they wanted to use it for their multi-billion-dollar businesses. But no one gave me a financial support.

Part of a reason is because most companies don't have an internal process to start supporting an open-source project. If they need to buy a license, that's fine, that's part of a usual business. But giving money away to "free" software? There's no precedent and hard to justify.
Given this situation, I'm seriously considering changing the mold/macOS license (not mold/Unix license) from AGPL to a commercial, source-available one. Something like individuals would be able to use it for free but companies have to pay.

I know some people are not happy about even thinking about it, and so am I. But to me it is more important to make the project viable long-term and grow into something that we can hire an engineer or two to accelerate the development. I haven't decided anything yet though!
#+end_quote
* DONE Hack The Box Ambassador
CLOSED: [2021-09-29 Wed]
:PROPERTIES:
:EXPORT_FILE_NAME: htb-ambassador
:END:

[[./images/header.jpg]]

For the last 18 months I have organized the dutch Hack The Box meetups. Due to COVID-19 they have all been as a digital meetup, but not less entertaining though.

During my time organizing the meetups the Hack The Box organization supports me in various ways; they give me stuff to hand out such as swag or VIP memberships, they help organize speakers for events when we don't have one ourselves and they provide me with Hack The Box goodies every once in a while.

One of the "goodies" is to be named Hack The Box Ambassador. This is mostly just a title, but a very cool one :D.

As I just celebrated my first year as Ambassador I was interviewed for the [[https://www.hackthebox.eu/blog/htb-ambassador-arjen-wiersma][Hack The Box Blog]]. A very nice article exploring my motivations to start hosting a meetup, how it ties in to my work as Lecturer at NOVI Hogeschool and the rewards I get from hosting the meetup.

On the blog I am no stranger however. In the last 6 articles I appear in 3 of them. The others explore the use of [[https://www.hackthebox.eu/blog/htb-and-academia-winning-combo][Hack The Box for academia]], to study the field of hacking, and a [[https://www.hackthebox.eu/blog/novi-story][case study]] on how NOVI Hogeschool utilizes the Hack The Box platform.

[[./images/on-the-blog.png]]

Very cool to be recognized in such a positive way by a great community. Thanks!

* DONE Badge Challenge 3
CLOSED: [2023-03-12 Sun 12:10]
:PROPERTIES:
:EXPORT_FILE_NAME: badge-challenge-3
:END:

** Original Post

During each in-person Hack The Box meetup I have a small badge challenge that will give the first solver of the challenge a price. at the meetup of March 2023 there will be a very nice little challenge to be done as well, a beautiful NOVI hoodie. You can already download the password protected zip archive. The password will be shared during the meetup opening words.

- [[/files/badge3.zip][The zip archive]] (sha1: 28e84243c79caefce06f62ba2c5d930de37a3439)

Good luck. Afterwards I will post a walkthrough of the challenge on this site. Badge Life is hard :)

** Walkthrough

As usual, the solving of this challenge did not go as expected.

When you first receive the challenge a quick binary analysis will show you that there is a condition of the passphrase. It has to *24* characters in length and the ascii value has to sum up to *2137*. During the meetup there were some hints as to how to find the passphrase, namely that I said that I posted in *LinkedIn* about the challenge and Salp had a /"credmp talks too much"/ on his badge. Sadly the hints were not picked up and people started writing bruteforcers for gigantic dictionaries. Eventually I updated my initial blog post to have all the information that was necessary so that the challenge could be solved.

A wise lesson here is to not rely on multiple sources for the challenge, and if so, make it much more direct. What should've been a fun, quick, bruteforcers ended up in a days long torment.

The original LinkedIn message on the badge challenge had all the information that was required. Lets check it out in the following figure.

#+ATTR_HTML: :alt The linkedin post
#+ATTR_HTML: :width 100%
[[./images/linkedin-badge-challenge.png]]

By creating a bruteforcer, as MrHaas did for the blog post, a script as the following could be created.

#+name: Solve code by MrHaas
#+begin_src python
from itertools import combinations, permutations
from tqdm import tqdm
import pwn

pwn.context.log_level = "error"

post = """
    Badge Challenge 3
March 12, 2023 · 1 min · Arjen Wiersma
During each in-person Hack The Box meetup I have a small badge challenge that will give the first solver of the challenge a price. at the meetup of March 2023 there will be a very nice little challenge to be done as well, a beautiful NOVI hoodie. You can already download the password protected zip archive. The password will be shared during the meetup opening words.
    The zip archive (sha1: 28e84243c79caefce06f62ba2c5d930de37a3439)
Good luck. Afterwards I will post a walkthrough of the challenge on this site.
"""


def ssum(s):
    return sum(ord(c) for c in s)


def iter_passphrases(words, n):
    for comb in combinations(words, n):
        if sum(len(word) for word in comb) != (24 - n + 1):
            continue
        if sum(ssum(word) for word in comb) != (2137 - (n - 1) * 32):
            continue

        for perm in permutations(comb):
            yield " ".join(perm)


if __name__ == "__main__":
    word_list = open("./dutch_common_wordlist.txt").read().split()
    words = [word.strip(".?!()#") for word in post.split()]
    overlap = set(word_list) & set(words) | {"Life"}

    for n in range(3, 6):
        print(f"Trying {n} words")
        for passphrase in tqdm(iter_passphrases(overlap, n)):
            with pwn.process(["./badge3", passphrase]) as ps:
                result = ps.recvall()

                if b"Sorry" not in result:
                    print(passphrase)
                    print(result.decode())
                    break
#+end_src

More interestingly, chatgpt can be leveraged to create a brute forcing program, however it is not very good. ChatGPT gets confused on how to use the itertools package to generate the combinations. However, it is a good starting template.

#+ATTR_HTML: :alt Getting help from ChatGPT
#+ATTR_HTML: :width 100%
[[./images/badge3-chatgpt.png]]

Finally, here is the actual Rust code for the challenge.

#+name: Challenge code in Rust
#+begin_src rust
use std::env;
use std::str;

fn main() {
    let mut args: Vec<String> = env::args().collect();

    println!(
"
Badge Life (in ASCII art)
");

    if args.len() == 1 {
        println!("Usage: {} passphrase", args[0]);
        return;
    }

    args.remove(0);
    let pass = args.join(" ");

    let mut sum = 0;
    for p in pass.chars() {
        sum = sum + (p as i32);
    }

    if pass.len() != 24 && sum != 2137 {
        println!(
            "That is not a correct passphrase (len {} sum {}), try again!",
            pass.len(),
            sum
        );
        return;
    }

    println!("That might work.... lets try it!");

    let password = pass.as_bytes();

    let encrypted = [
        166, 245, 144, 245, 161, 25, 252, 210, 105, 138, 33, 57, 160, 128, 18, 25, 38, 0, 0, 0, 0,
        0, 0, 0, 6, 171, 134, 183, 188, 103, 63, 69, 199, 190, 26, 116, 174, 217, 135, 232, 211,
        26, 102, 245, 226, 186, 82, 70, 104, 59, 170, 231, 162, 92, 120, 130, 135, 108, 134, 108,
        22, 81,
    ];

    let plain = simplestcrypt::deserialize_and_decrypt(&password[..], &encrypted);

    match plain {
        Ok(v) => {
            let conv = str::from_utf8(&v);
            match conv {
                Ok(key) => println!("Here is the key: {:?}", key),
                Err(_) => println!("Sorry, it was not the right phrase"),
            }
        }
        Err(_) => {
            println!("Sorry, it was not the right phrase");
            return;
        }
    }
}
#+end_src

The passphrase was: *Badge Life at The meetup*

* DONE Open Universiteit: Software Quality Management :education:
CLOSED: [2023-03-25 Sat 16:31]
:PROPERTIES:
:EXPORT_FILE_NAME: ou-sqm
:END:

** Background

I have been working on getting my Master's degree in Software Engineering. To do this I have started following courses at the Dutch Open Universiteit. They have a Master's program that takes 2 years and you are able to follow it from home.

As this is my first post on the courses, I will give some background. As a teacher it is recommended to have a Master's degree. As I had a whole lot of work experience my teaching activities were not a problem, but from an  overall point of view I was advised to pursue an Master degree. As my highest educational level up to now is a Bachelor I first had to follow a pre-master program before I could start the Master program. I will write about my experiences of the pre-master program later.

** Software Quality Management

I just finished the Software Quality Management course. It was a fun course that focused on the maintainability of code and measuring objective quality metrics. As is usual in a Master you read a lot of papers on the topic, from McCabe's complexity measure to Fuggetta et al. on the evolution of the software development process. All these papers were very interesting and have given me insights into the evolution of software development. It was enlightening to offset those papers with my own experience.

Most of the papers are from the late 1990's up to the early 2010's. During that time I worked in Silicon Valley and within the Dutch startup environment. All these companies were on the frontline of new technologies and methodologies. The papers hit home most of the time. Several papers on the implementation of Scrum and how software evolves felt a bit one-sided from an academic point of view, but that did not bother me too much.

** The Rascal Programming Language

One of the more interesting parts of the course was to write our own metric collection and visualization in the [[https://www.rascal-mpl.org/][Rascal Meta Programming Language]]. Rascal is a domain specific language that allows you to reason about source code by building models and then querying these models.

In my group we implemented metrics collection for unit size, complexity, duplication and code coverage (testing). These were very interesting problems to attack and the result was a very cool visualization using D3js.

The project hit a happy place for me. As a result I going to work on an extension for Rascal for my Master Thesis.

** References

Some of the articles that were used in the course are listed below.

- McCabe (1976) A Complexity Measure, IEEE Transactions on Software Engineering.
- Fuggetta, Di Nitto (2014) Software Process, ACM.
- Bennett, Rajlich (2000) Software Maintenance and Evolution: A Roadmap, Association for Computing Machinery.

***

* DONE Starting my Master Thesis :education:
CLOSED: [2023-04-13 Thu 22:15]
:PROPERTIES:
:EXPORT_FILE_NAME: starting-master-thesis
:END:


Today, I took the first step towards starting my master's thesis. I have decided to document my journey and experiences on my blog. Given that the thesis will play a pivotal role in my life for the next nine months, I expect it to be a thrilling journey.

** Finding a topic

As a student at [[https://www.ou.nl][Open Universiteit]] in The Netherlands, I had the opportunity to work with the [[https://rascal-mpl.org][Rascal programming language]] during the Software Quality Management course. I found the language intriguing and enjoyed working with it throughout the module. After consulting with my professor, we brainstormed various possibilities for my master's thesis topic, ultimately settling on the creation of a visualization library for the language.

Although I had to complete my Software Architecture course before embarking on my thesis, I finally had the chance to visit the [[https://www.cwi.nl/en/][Center for Mathematics and Informatics (CWI)]], an important organization in the Netherlands. The CWI has a large department devoted to quantum computing and is responsible for developing and maintaining the Rascal programming language, in addition to being the [[https://www.cwi.nl/en/about/history/][first entity to connect to the internet and register a ".nl" domain name]]. Oh, and it is also the place where Python was invented. During my visit, we discussed a plethora of options, including reusable components and compositional visualizations, but ultimately decided to focus on projectional editors.

Projectional editors are a type of text editor that allows users to work with a representation of the code's abstract syntax tree (AST), instead of working with the code directly. This approach enables users to work with a higher-level representation of the code, which can make it easier to comprehend and manipulate complex code structures. Typically, users create and edit code in projectional editors by selecting elements from a palette or menu and positioning them in a visual representation of the code's syntax tree. The editor then automatically generates the corresponding code based on the user's selections. This approach is especially useful for languages with intricate syntax or when developing domain-specific languages.

To create a visualization of source code in the form of a diagram, a domain-specific language (DSL) is required to describe the visualization. A DSL is a programming language designed to solve problems in a specific domain or context. In this case, a DSL would be used to describe the structure and layout of the visualization of the source code.

Currently, there is no existing DSL that can be used to describe the visualization of source code. Therefore, as part of the master's thesis, the focus will be on creating a context-free grammar (CFG) capable of generating the DSL required for the visualization. The CFG will define the syntax and structure of the language, including the rules and patterns used to create the visual representation of the code.

Once the CFG is created, the DSL can be generated and used to create the visualization of the source code in the form of a diagram. This visualization will enable users to reason about their code in a high-level manner, helping to identify and understand complex code structures and relationships.

** Context-Free Grammars

A context-free grammar (CFG) is a formalism used to describe the syntax of a formal language. A CFG consists of a set of rules that define how strings of symbols can be constructed in the language. The rules in a CFG specify how non-terminal symbols can be replaced with sequences of terminal and non-terminal symbols.

A non-terminal symbol represents a syntactic category or type of element in the language, while a terminal symbol represents a basic unit of meaning or a symbol that cannot be further reduced. The rules in a CFG define how non-terminal symbols can be replaced by sequences of terminal and non-terminal symbols, and how these sequences can be combined to form valid strings in the language.

Consider the following CFG:

#+begin_src
S -> aSb | ε
#+end_src

In this CFG, ~S~ is a non-terminal symbol that represents a string of the form ~a^n b^n where n >= 0~. The rule ~S -> aSb~ specifies that a string of the form ~a^n b^n~ can be constructed by taking a string of the form ~a^(n-1) b^(n-1)~ and appending an ~a~ to the beginning and a ~b~ to the end. The rule ~S -> ε~ specifies that the empty string is also a valid string of the language.

Using this CFG, we can generate the following strings:

#+begin_src
ε
ab
aabbb
aaabbbb
aaaabbbbb
#+end_src

To generate the string aaaabbbbb, we can use the following sequence of derivations:

#+begin_src
S => aSb          (apply rule S -> aSb)
  => aaSbb        (apply rule S -> aSb)
  => aaaSbbb      (apply rule S -> aSb)
  => aaaaSbbbb    (apply rule S -> aSb)
  => aaaabbbbb    (apply rule S -> ε)
#+end_src

Note that at each step in the derivation, we apply a rule to replace a non-terminal symbol with a sequence of terminal and non-terminal symbols, until we arrive at a string composed entirely of terminal symbols (i.e., the empty string or a string of the form ~a^n b^n~).

** Moving forward

The preparation phase for the master's thesis at Open Universiteit spans 11 weeks, followed by 22 weeks of research and writing. As I am just starting the preparation phase, I anticipate the topic to evolve over time, and I look forward to sharing my journey with you.

* DONE Using AI in academics
CLOSED: [2023-05-20 Sat 11:00]
:PROPERTIES:
:EXPORT_FILE_NAME: ai-in-academics
:END:

Using AI, in particular generative models such as GPT, are in contention within academics. The purity of academics resides in students writing on their research and having their work peer-reviewed. But how can you now be sure that the student wrote the paper and how can you trust its content? Many universities, including the OU have written about it. The OU published an article in [[https://modulair.ou.nl/modulair-2023-april/chatgpt-in-het-onderwijs][Modulair about it]]. Generally, the consensus seems to be that it is ok to use AI as an assistant, but you must write your texts.

For me AI has proven to be a valuable assistant. Here are some ways in which I found AI to be extremely useful:

** Blank page syndrome

"Blank page syndrome" refers to the common experience of feeling stuck and overwhelmed when faced with a blank document. It can hinder productivity and creativity in academic writing. Thankfully, AI-powered tools have been developed to combat this syndrome. Utilizing natural language processing algorithms, these tools can generate ideas, provide content suggestions, and even create outlines to jumpstart the writing process. Examples of such tools include [[https://chat.openai.com][ChatGPT]] and [[https://ai.facebook.com/blog/large-language-model-llama-meta-ai/][LLaMA]], which have proven to be invaluable resources for overcoming this challenge.

Take the following, [[https://medium.com/@ryan.craven.qa/mastering-ai-prompts-comprehensive-guide-for-better-output-68aa2d104f21][simplified]], prompt:

#+begin_quote
I am writing a blog post on using AI to write academic papers. I want to cover "blank page syndrome", "finding related works" and "spelling and grammar correction". Your task is to work as my writing assistant. Write an outline for this article.
#+end_quote

Results in the following outline:

#+begin_example
I. Introduction
A. Brief explanation of the challenges faced in academic writing
B. Introduction to the role of AI in overcoming these challenges

II. Understanding "Blank Page Syndrome"
A. Definition and common experiences associated with "blank page syndrome"
B. Causes and psychological factors contributing to the syndrome
C. Introduction to AI-powered tools that can help combat it

III. Overcoming "Blank Page Syndrome" with AI
A. AI-based content generation tools
1. Natural language processing algorithms for generating ideas
2. Examples of AI tools that provide content suggestions and outlines

IV. Finding Related Works Efficiently
A. Importance of literature review and related work in academic writing
B. Challenges in finding relevant sources and connections
C. AI-driven approaches to streamline the process
1. Text mining and semantic analysis algorithms
2. Machine learning techniques for identifying related works
D. Examples of AI tools for efficient literature search and recommendation

V. Improving Spelling and Grammar Accuracy
A. Significance of proper spelling and grammar in academic papers
B. Limitations of traditional spell checkers and grammar tools
C. AI-powered proofreading tools for enhanced accuracy
1. Natural language processing algorithms for grammar checks
2. Machine learning models for spelling and punctuation correction
D. Examples of popular AI-based writing assistant tools

VI. Ethical Considerations and Human Oversight
A. Discussing concerns regarding overreliance on AI in writing
B. Importance of human oversight and critical thinking
C. Addressing potential biases and limitations in AI-driven writing tools

VII. Benefits and Impact of AI in Academic Writing
A. Increased productivity and efficiency for researchers
B. Enhanced accuracy and clarity in written work
C. Facilitation of interdisciplinary research and collaboration

VIII. Future Possibilities and Challenges
A. Advancements in AI technologies for academic writing
B. Integration of AI into existing writing platforms and workflows
C. Challenges and considerations for the future of AI in academic writing

IX. Conclusion
A. Recap of the benefits of using AI in academic writing
B. Encouragement for researchers to explore and utilize AI tools
C. Final thoughts on the transformative potential of AI in academic writing

Make sure to expand on each section with relevant examples, case studies, and practical tips to provide a comprehensive understanding of how AI can assist in academic writing.
#+end_example

How is that for a starter outline? Yes, you will have to work on the structure and the ideas, but you get to start with a solid base. It frees you from the initial "get it on paper" anxiety.

** Finding related work

Conducting a comprehensive literature review and identifying relevant related works is crucial for academic writing. However, this task can be time-consuming and overwhelming. AI-driven approaches have emerged to streamline the process and provide researchers with efficient ways to discover related works. By leveraging text mining, semantic analysis, and machine learning techniques, AI tools can analyze vast databases of scholarly articles, uncover hidden connections, and recommend relevant sources. Tools like ~scite_~'s Assistant (https://scite.ai/assistant) have proven to be invaluable assets for researchers, enabling them to save time and access a wealth of knowledge with ease.

[[./images/scite-assistant.png]]

** Improving spelling and grammar accuracy

Accurate spelling and proper grammar are essential in academic writing to effectively convey ideas. While traditional spell checkers and grammar tools have limitations, AI-powered proofreading tools have significantly improved accuracy and efficiency. These tools leverage natural language processing algorithms and machine learning models to identify grammar mistakes, spelling errors, and punctuation inconsistencies. [[https://www.grammarly.com/][Grammarly]], a widely recognized tool, has gained acclaim for its ability to enhance the overall quality of written work, ensuring polished and error-free academic papers.

[[./images/grammarly.png]]

** Ethical Considerations and Human Oversight

While AI tools provide invaluable assistance, it's important to acknowledge the importance of human oversight and critical thinking in academic writing. Researchers should exercise caution and verify the suggestions provided by AI tools. Additionally, addressing potential biases and limitations in AI-driven writing tools is crucial to ensure fair representation and accurate information.

** Benefits and Impact of AI in Academic Writing

The integration of AI into academic writing processes holds tremendous potential. Researchers can benefit from increased productivity, as AI tools expedite tasks that would otherwise be time-consuming. The enhanced accuracy and clarity in written work contribute to improved quality, enabling researchers to convey their ideas more effectively. Moreover, AI-powered tools facilitate interdisciplinary research, knowledge dissemination, and collaboration, breaking down barriers and fostering innovation across academic disciplines.

** Future Possibilities and Challenges

The future of AI in academic writing looks promising. Advancements in AI technologies, including more sophisticated natural language processing algorithms and intelligent content generation models, will further enhance the capabilities of AI tools. Integrating AI into existing writing platforms and workflows will streamline the academic writing process, making it more accessible and user-friendly. However, challenges such as addressing

** Conclusion

In conclusion, the utilization of AI tools in academic writing can have a transformative impact on researchers. By leveraging AI-powered text generation and proofreading capabilities, academics can experience a multitude of benefits. Firstly, AI tooling allows for increased writing velocity, enabling researchers to produce content more efficiently. With AI's assistance, the time-consuming process of meticulously correcting spelling and grammar errors is significantly reduced, freeing up valuable time for researchers to focus on the critical thinking process. As a result, the overall quality of written work can be elevated, ensuring that ideas are effectively conveyed and scholarly contributions are of the highest standard. By embracing AI tooling, academics can embrace a more streamlined and effective approach to writing, empowering them to make significant strides in their research endeavors.

[[./images/chatgpt-ai-conclusion.png]]

* DONE Perfectionism leads to procrastination and paralysis :mental:health:
CLOSED: [2023-06-06 Tue 08:15]
:PROPERTIES:
:EXPORT_FILE_NAME: perfectionsim-procrastination
:END:

Working on my thesis research proposal has been quite the journey, and not always in the direction I would have chosen. A personal revelation that struck me during the process is the tight and rather vexing relationship between perfectionism, procrastination, and paralysis.

It's often said that the perfect is the enemy of the good. In my quest for the 'just right' words to articulate my thoughts, I found this saying to be glaringly accurate. The ticking clock became a dull backdrop to my cerebral scavenger hunt. My concentration started to drift and instead of zeroing in on my research proposal, I found myself fixated on, of all things, the color scheme of my desktop environment.

I got tangled up in a fascinating yet peculiar rabbit hole - the slightly discordant appearance of my Emacs compared to my i3 top bar. This, of course, necessitated immediate rectification, just as I was contemplating that elusive sentence. I spent the entire evening indulging in the color-coded symphony of [[https://github.com/catppuccin/][Catppuccin]]. Updating the aesthetic of my terminal, tmux, Emacs, Firefox, and i3 configuration was a strange kind of thrill. By the end, I had a beautifully cohesive desktop environment. And yet, that pesky sentence still hung in the air, unwritten.

[[./images/catppuccin.png]]

[[https://drkarenmcdowell.com/][Dr. Karen McDowell]], a noted advocate for mental wellness, hits the nail on the head when she says, "When you tackle perfectionism, you’re less likely to procrastinate.” Her wisdom tells us that striving for flawlessness not only impedes our progress but also mars the satisfaction we derive from our achievements.

So, how do we break free from this perfection-procrastination paralysis? Dr. McDowell offers a straightforward, seven-step plan:

1. Consciously lower the bar: Acknowledge that it's okay not to be perfect.
2. Keep your tasks bite-sized: Manageable chunks are less daunting.
3. Track your time: Understand where your hours are going.
4. Surround yourself with positive support: Encouragement helps to keep your spirits high.
5. Practice saying ‘no’: Respect your capacity and set boundaries.
6. Use the reward system: Motivate yourself with small incentives.
7. Incorporate mindfulness: Stay in the present and appreciate your progress.

Now, bear in mind, trying to implement all these changes at once might be a bit like swallowing an elephant whole - impossible and frankly quite unpleasant. The key is to choose a few steps to begin with and gradually incorporate the others. For me, steps one to three seem like a good starting point.

As I venture on this path, I hope to transform my approach towards work, shedding the weight of perfection and embracing the joy of creation. And perhaps, in doing so, I might finally write that sentence.

* DONE Embarking on a Journey to Revolutionize Code Editing: The Birth of "BiDE"
CLOSED: [2023-09-04 ma 20:44]
:PROPERTIES:
:EXPORT_FILE_NAME: the-start-of-bide
:END:

As the warm haze of summer gives way to the crisp air of autumn, the season marks a pivotal moment in my academic journey: the commencement of my Master's thesis project. Having successfully had my research proposal accepted earlier this year, I now face the last leg of this marathon—bringing my theoretical framework to life.

** The Powerhouse Partnership: Open Universiteit and CWI

While undertaking a Master's thesis is a significant endeavor on its own, I always have to make it more complex. My research will be a collaborative effort between two prominent institutions: the Open Universiteit and the Centrum Wiskunde & Informatica (CWI).

The CWI is not just another research facility; it is a cornerstone in the Dutch digital landscape. It has been the crucible for pioneering advancements that have indelibly shaped our digital world. To name a few highlights, CWI is the hallowed ground where the first-ever internet connection was established, where the Python programming language was conceived, and where countless other groundbreaking technological milestones have taken root. In my venture, I will be joining forces with the SWAT group, a team that specializes in Software Analysis and Transformation.

** Introducing "BiDE": Bridging the Gap Between Code and Visualization

At the crux of my research is the creation of a novel visual language designed to facilitate intuitive code editing. Dubbed "BiDE", short for Bidirectional Diagrammatic Editors, this language aims to serve as a transformative tool in how we understand and manipulate code.

Imagine a scenario where you're faced with an enigmatic, complex piece of code—a labyrinth of loops, conditionals, and functions. Traditionally, you would have to painstakingly dissect each line, trying to visualize the underlying architecture mentally. With BiDE, that approach is poised to become a relic of the past. Instead, a streamlined diagrammatic representation of the code will pop up, offering you a high-level overview.

What sets BiDE apart is its bidirectional functionality. Not only can you comprehend the structure of the code through its visual depiction, but you can also make edits either in the diagrammatic interface or the source code. The brilliance lies in their synchrony; changes in one environment are automatically reflected in the other, keeping both up-to-date in real-time.

** A Journey of Discovery, Planning, and Adaptation

As I've begun work on my thesis, I've quickly noticed that the process is surprisingly open-ended. Aside from regular meetings with my supervisor, there's not much of a predefined structure. This makes the ability to plan and organize my work even more crucial than before. Without a strong framework, it's easy to get lost in the complexity of the project. So, while the flexibility offers a lot of freedom, it also comes with the responsibility to be my own taskmaster, making sure each piece of the puzzle fits just right.

** Staying Connected

As I move forward, I will update you on the developments, challenges, and breakthroughs of this endeavor.

* DONE Advent of Code 2023 Day 1
CLOSED: [2023-12-02 za 14:39]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-1
:END:

The [[https://www.adventofcode.com][Advent of Code]] has started again. At [[https://www.novi.nl][NOVI]] we participate with a group of our students. We use the AoC throughout the entire curriculum as practice exercises to learn new programming languages or the application of data-structures and algorithms.

Day 1 was a tricky start for most people. Part 1 was not too bad, but part 2 tripped most people up. I guess the idea was that you would have to solve the challenge with an array iteration, but most students tripped up. They tried to match each word and replace the occurrence in the text, running head-on into the edge-case where 2 numbers overlap, such as "eightwo".

Here is my solution using the Go programming language:

#+begin_src go
package main

import (
	"fmt"
	"os"
	"strings"
	"unicode"
)

func part1(lines []string) {
	ans := 0
	for _, v := range lines {
		var ints []int
		for _, c := range v {
			if unicode.IsDigit(c) {
				ints = append(ints, int(c-'0'))
			}
		}
		if len(ints) == 0 {
			continue
		}
		ans += ints[0]*10 + ints[len(ints)-1]
	}
	fmt.Println("Part 1: ", ans)
}

func part2(lines []string) {
	ans := 0
	for _, v := range lines {
		var ints []int
		for x := 0; x < len(v); x++ {
			for k, val := range []string{"one", "two", "three", "four", "five", "six", "seven", "eight", "nine"} {
				if strings.HasPrefix(v[x:], val) {
					ints = append(ints, k+1)
				}
			}
			if unicode.IsDigit(rune(v[x])) {
				ints = append(ints, int(v[x]-'0'))
			}
		}

		if len(ints) == 0 {
			continue
		}
		ans += ints[0]*10 + ints[len(ints)-1]
	}

	fmt.Println("Part 2: ", ans)
}

func main() {
	content, _ := os.ReadFile("2023/Day01/input.txt")

	lines := strings.Split(string(content), "\n")

	part1(lines)
	part2(lines)
}

#+end_src

* DONE Advent of Code 2023 Day 2
CLOSED: [2023-12-02 za 14:41]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-2
:END:

Day 2 was another fun challenge. Lots of splitting of strings. I wonder if there is a better way to filter out the min and max value from the separate grabs.

I am sure I will not be able to complete all challenges this year, but so far so good.

#+begin_src go
package main

import (
	"fmt"
	"os"
	"strconv"
	"strings"
)

type Grab struct {
	red, green, blue int
}

type Game struct {
	id    int
	grabs []Grab
}

func main() {
	content, _ := os.ReadFile("2023/Day02/input.txt")

	var input []Game
	for g, l := range strings.Split(strings.TrimSpace(string(content)), "\n") {
		game := Game{}
		game.id = g + 1
		parts := strings.Split(l, ":")
		grabs := strings.Split(parts[1], ";")
		for _, h := range grabs {
			grab := Grab{}
			for _, rgb := range strings.Split(h, ",") {
				color := strings.Split(strings.TrimSpace(rgb), " ")
				i, _ := strconv.Atoi(color[0])
				switch color[1] {
				case "red":
					grab.red = i
				case "green":
					grab.green = i
				case "blue":
					grab.blue = i
				}
			}
			game.grabs = append(game.grabs, grab)
		}
		input = append(input, game)
	}

	max := Grab{
		red:   12,
		green: 13,
		blue:  14,
	}

	var possible []Game
outer:
	for _, game := range input {
		for _, grab := range game.grabs {
			if grab.red > max.red || grab.green > max.green || grab.blue > max.blue {
				continue outer
			}
		}
		// fmt.Println("Possible game: ", game)
		possible = append(possible, game)
	}

	sum := 0
	for _, g := range possible {
		sum += g.id
	}
	fmt.Println("Part 1: ", sum)

	var powers []Grab
	for _, game := range input {
		min := Grab{
			red:   0,
			green: 0,
			blue:  0,
		}
		for _, grab := range game.grabs {
			if grab.red > min.red {
				min.red = grab.red
			}
			if grab.green > min.green {
				min.green = grab.green
			}
			if grab.blue > min.blue {
				min.blue = grab.blue
			}
		}
		powers = append(powers, min)
	}

	sum = 0
	for _, x := range powers {
		sum += x.red * x.green * x.blue
	}
	fmt.Println("Part 2: ", sum)
}

#+end_src

* DONE Advent of Code 2023 Day 3
CLOSED: [2023-12-03 zo 12:38]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-3
:END:

Day 3 was quite something. I think that in an attempt to make it harder for AI to solve the puzzles the creators also increased the difficulty level of the base puzzles a little too much. The test was not very clear as to what should happen with negative numbers and it might trip people up. The puzzle itself is a great to exercise grid knowledge as you have to work with neighbors and you have to extend the numbers when you find them. Part 2 was just some bookkeeping on my existing implementation, so it was not too much work.

As a note; I first started out with a list of Points, keeping track of the numbers in a coordinate system. This failed miserably :).

#+begin_src go
package main

import (
	"fmt"

	"arjenwiersma.nl/aoc/internal/aoc"
)

type Point struct {
	Y, X int
}

func IsDigit(b byte) bool {
	return b-'0' >= 0 && b-'0' <= 9
}

func main() {
	lines := aoc.AsLines("2023/Day03/input.txt")

	ygrid := len(lines)
	xgrid := len(lines[0])

	grid := make([][]byte, ygrid)
	for y, l := range lines {
		grid[y] = make([]byte, xgrid)
		for x := 0; x < len(l); x++ {
			grid[y][x] = l[x]
		}
	}

	neighbors := [][]int{
		{-1, -1}, {0, -1}, {1, -1},
		{-1, 0}, {0, 0}, {1, 0},
		{-1, 1}, {0, 1}, {1, 1},
	}

	gears := make(map[Point][]int)
	sum := 0
	for y := 0; y < ygrid; y++ {
		for x := 0; x < xgrid; x++ {
			num := 0
			hasSymbol := false
			isGear := false
			var gearCoord Point
			for IsDigit(grid[y][x]) {
				num = num*10 + int(grid[y][x]-'0')
				for _, n := range neighbors {
					if y+n[1] >= 0 && y+n[1] < ygrid &&
						x+n[0] >= 0 && x+n[0] < xgrid {
						v := grid[y+n[1]][x+n[0]]
						if !IsDigit(v) && v != '.' {
							if v == '*' {
								isGear = true
								gearCoord = Point{X: x + n[0], Y: y + n[1]}
							}
							hasSymbol = true
						}
					}
				}
				x += 1
				if x >= xgrid {
					break
				}
			}
			if num > 0 && hasSymbol {
				if isGear {
					gears[gearCoord] = append(gears[gearCoord], num)
				}
				sum += num
			}
		}
	}

	fmt.Println("Part 1: ", sum) // 498559

	sum = 0
	for _, v := range gears {
		if len(v) == 2 {
			sum += v[0] * v[1]
		}
	}
	fmt.Println("Part 2: ", sum) // 72246648
}

#+end_src

* DONE Advent of Code 2023 Day 4
CLOSED: [2023-12-04 Mon 23:16]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-4
:END:

The difficulty is going up and down. This day was quite easy in comparison to yesterday. Today it was about parsing some numbers and finding a set of winning numbers.

As I am doing these puzzles in Go I found out that there is no default =set= type. There is an implementation by HashiCorp named [[https://github.com/hashicorp/go-set][go-set]] that fills this void. I did not use an external package (I try to avoid them while doing AoC), but I am very tempted to pull that package in.

Here is my solution using lists.

#+begin_src go
package main

import (
	"fmt"
	"math"
	"strings"

	"arjenwiersma.nl/aoc/internal/aoc"
)

func main() {
	lines := aoc.AsLines("2023/Day04/input.txt")

	ans := 0
	counts := make([]int, len(lines))

	for x := 0; x < len(lines); x++ {
		counts[x] = 1
	}

	for i, l := range lines {
		nums := strings.Split(l, ":")
		parts := strings.Split(nums[1], "|")
		myInts := aoc.StrToInts(strings.Split(parts[1], " "))
		winInts := aoc.StrToInts(strings.Split(parts[0], " "))

		count := 0
		for _, v := range myInts {
			for _, x := range winInts {
				if x == v {
					count += 1
				}
			}
		}
		if count > 0 {
			c := int(math.Pow(2, float64(count)-1))
			for x := 1; x <= count; x++ {
				counts[i+x] += counts[i]
			}
			ans += c
		}
	}
	fmt.Println("Part 1: ", ans)
	ans = 0
	for _, v := range counts {
		ans += v
	}
	fmt.Println("Part 2: ", ans)
}

#+end_src

* DONE Advent of Code 2023 day 5
CLOSED: [2023-12-09 za 07:13]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-5
:END:

Today was an interesting problem. We are basically given a map to follow based on a number, possibly transforming the number at each step. With a single number this is quite simple, just apply the rules and step through each set of transformations. The problem becomes tricky when it turns out we have to deal with enormous ranges of numbers. On the subreddit some people reported their implementation to take hours and use 20GB of memory.

Luckily there is always a fast solution. In this case it was using ranges of numbers to go through the transformations, so just taking the first number and then creating a (new) range out of the transformation instead of each individual number.

#+begin_src go
package main

import (
	"fmt"
	"log"
	"math"
	"os"
	"strconv"
	"strings"
	"time"

	"arjenwiersma.nl/aoc/internal/aoc"
)

type Range struct {
	d, s, r int
}

func (r *Range) transform(i int) int {
	if i >= r.s && i <= r.s+r.r-1 {
		delta := i - r.s
		return r.d + delta
	}

	return i
}

type Segment struct {
	from, to int
}

func main() {
	content, _ := os.ReadFile("2023/Day05/input.txt")
	segments := strings.Split(strings.TrimSpace(string(content)), "\n\n")

	seedStr := strings.Split(segments[0][6:], " ")
	var seed []int
	for _, x := range seedStr {
		if strings.TrimSpace(x) == "" {
			continue
		}
		s, err := strconv.Atoi(strings.TrimSpace(x))
		if err != nil {
			log.Fatal(s, err)
		}
		seed = append(seed, s)
	}
	// fmt.Println("Seeds: ", seed)

	maps := make([][]Range, len(segments)-1)
	for i, s := range segments[1:] {
		l := strings.Split(s, "\n")
		maps[i] = make([]Range, len(l)-1)
		for j, x := range l[1:] {
			var m Range
			fmt.Sscanf(x, "%d %d %d", &m.d, &m.s, &m.r)
			maps[i][j] = m
		}
	}

	startTime := time.Now()

	min := math.MaxInt
	for _, s := range seed {
		c := s
	trans:
		for _, m := range maps {
			for _, t := range m {
				source := c
				c = t.transform(c)
				if c != source {
					continue trans
				}
			}
		}
		if c < min {
			min = c
		}
	}
	endTime := time.Now()
	elapsed := endTime.Sub(startTime)
	fmt.Printf("Part 1: %d (%v)\n", min, elapsed) // 662197086

	startTime = time.Now()
	// starting segments
	var S []Segment
	for i := 0; i < len(seed); i += 2 {
		S = append(S, Segment{seed[i], seed[i] + seed[i+1]})
	}

	for _, m := range maps {
		var A []Segment
		for _, t := range m {
			var nS []Segment
			for _, s := range S {
				nA, nnS := createSegments(s, t)
				A = append(A, nA...)
				nS = append(nS, nnS...)
			}
			S = nS
		}
		S = append(S, A...)
	}
	min = math.MaxInt

	for _, s := range S {
		min = aoc.Min(s.from, min)
	}
	endTime = time.Now()
	elapsed = endTime.Sub(startTime)
	fmt.Printf("Part 2: %d (%v)\n", min, elapsed) // 52510809
}

func createSegments(s Segment, t Range) (A []Segment, nS []Segment) {
	before := Segment{s.from, aoc.Min(s.to, t.s)}
	inter := Segment{aoc.Max(s.from, t.s), aoc.Min(t.s+t.r, s.to)}
	after := Segment{aoc.Max(t.s+t.r, s.from), s.to}

	if before.to > before.from {
		nS = append(nS, before)
	}
	if inter.to > inter.from {
		inter.from = inter.from - t.s + t.d
		inter.to = inter.to - t.s + t.d
		A = append(A, inter)
	}
	if after.to > after.from {
		nS = append(nS, after)
	}

	return A, nS
}
#+end_src

* DONE Advent of Code 2023 day 6
CLOSED: [2023-12-09 za 07:16]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-6
:END:

Day 6 turned out to be the easiest day in the range so far. A simple implementation of the algorithm was more than sufficient.

I later learned that it was a quadratic function. On the subreddit Deatranger999 said:

#+begin_quote
If you hold down the button for x seconds, then you will beat the distance if the quadratic x^2 - t x + d is at most 0, where t is the total time of the race and d is the distance you'd like to beat. So I just plugged each one into WolframAlpha, found the roots, and then calculated the number of integers between the two roots.
#+end_quote

My solution was to bruteforce :)

#+begin_src go
package main

import (
	"fmt"
	"strconv"
	"strings"

	"arjenwiersma.nl/aoc/internal/aoc"
)

func main() {
	lines := aoc.AsLines("2023/Day06/input.txt")

	var times []int
	for _, t := range strings.Split(lines[0], " ")[1:] {
		s := strings.TrimSpace(t)
		if s == "" {
			continue
		}
		i, _ := strconv.Atoi(s)
		times = append(times, i)
	}
	var distances []int
	for _, t := range strings.Split(lines[1], " ")[1:] {
		s := strings.TrimSpace(t)
		if s == "" {
			continue
		}
		i, _ := strconv.Atoi(s)
		distances = append(distances, i)
	}

	result := make([]int, len(times))

	for i := 0; i < len(times); i++ {
		for t := 0; t < times[i]; t++ {
			d := t * (times[i] - t)
			if d > distances[i] {
				result[i] += 1
			}
		}
	}

	ans := 1
	for _, c := range result {
		ans *= c
	}

	fmt.Println("Part 1: ", ans)

	nT, _ := strconv.Atoi(fmt.Sprintf("%d%d%d%d", times[0], times[1], times[2], times[3]))
	nD, _ := strconv.Atoi(fmt.Sprintf("%d%d%d%d", distances[0], distances[1], distances[2], distances[3]))

	ans = 0
	for t := 0; t < nT; t++ {
		d := t * (nT - t)
		if d > nD {
			ans += 1
		}
	}
	fmt.Println("Part 2: ", ans)

}
#+end_src

* DONE Advent of Code 2023 day 7
CLOSED: [2023-12-09 za 07:18]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-7
:END:

Today we learned about CamelCards, a game of poker meant to play on the back of a camel. The most interesting part here was the parsing of the cards and figuring out how to properly rank them. Part 2 turned out to be as easy as tracking Jokers.

#+begin_src go
package main

import (
	"fmt"
	"sort"
	"strconv"
	"strings"
	"time"

	"arjenwiersma.nl/aoc/internal/aoc"
)

type Card struct {
	bid    int
	hand   []int
	jokers int
}

func (c *Card) strongerThen(o *Card) bool {
	for i, v := range c.hand {
		if v > o.hand[i] {
			return true
		} else if v < o.hand[i] {
			return false
		}
	}
	return false
}

func (c *Card) rank() int {
	freq := make([]int, 15)
	for _, v := range c.hand {
		if v == 1 { // skip counting the joker
			continue
		}
		freq[v]++
	}

	sort.Ints(freq)

	freq[len(freq)-1] += c.jokers
	strength := 2 * freq[len(freq)-1]
	// full house and 2 pair
	if freq[len(freq)-2] == 2 {
		strength += 1
	}
	return strength
}

func NewCard(s string, bid int, p2 bool) *Card {
	c := &Card{}
	c.bid = bid
	c.jokers = 0
	for p := 0; p < len(s); p++ {
		if s[p]-'0' >= 2 && s[p]-'0' <= 9 {
			c.hand = append(c.hand, int(s[p]-'0'))
		} else {
			x := 10
			switch s[p] {
			case 'A':
				x = 14
			case 'K':
				x = 13
			case 'Q':
				x = 12
			case 'J':
				if p2 {
					c.jokers += 1
					x = 1
				} else {
					x = 11
				}
			case 'T':
				x = 10
			}
			c.hand = append(c.hand, x)
		}
	}
	return c
}

func (c *Card) String() string {
	return fmt.Sprintf("%v (%d)", c.hand, c.bid)
}

func main() {
	content := aoc.AsLines("2023/Day07/input.txt")

	var cards []*Card
	for _, v := range content {
		p := strings.Split(v, " ")
		b, _ := strconv.Atoi(p[1])
		c := NewCard(p[0], b, false)
		cards = append(cards, c)
	}

	startTime := time.Now()
	lessFunc := func(i, j int) bool {
		if cards[i].rank() == cards[j].rank() {
			return cards[j].strongerThen(cards[i])
		}
		return cards[i].rank() < cards[j].rank()
	}

	sort.Slice(cards, lessFunc)

	res := 0
	for i, c := range cards {
		res += (i + 1) * c.bid
	}

	endTime := time.Now()
	elapsed := endTime.Sub(startTime)
	if 251216224 != res {
		panic("Wrong answer")
	}
	fmt.Printf("Part 1: %d (%v)\n", res, elapsed) // 251216224

	cards = []*Card{}
	for _, v := range content {
		p := strings.Split(v, " ")
		b, _ := strconv.Atoi(p[1])
		c := NewCard(p[0], b, true)
		cards = append(cards, c)
	}
	startTime = time.Now()

	sort.Slice(cards, lessFunc)

	res = 0
	for i, c := range cards {
		res += (i + 1) * c.bid
	}
	endTime = time.Now()
	elapsed = endTime.Sub(startTime)
	if 250825971 != res {
		panic("Wrong part 2")
	}
	fmt.Printf("Part 2: %d (%v)\n", res, elapsed) // 250825971
}

#+end_src

* DONE Advent of Code 2023 day 8
CLOSED: [2023-12-09 za 07:27]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-8
:END:

Somewhat suspicious of 2 easy days we end up at Day 8. A simple map to follow again, from one key follow the instructions until we hit =ZZZ=. Part 2 had us do it for several keys at once, with the goal to find the spot where they all converge. This can take *forever*, erhm, a long time.

So there has to be a math type solution to this problem. It turns out to be a Least Common Multiple problem. It is the smallest positive integer that is divisible by two or more numbers without leaving a remainder. To find the LCM of two or more numbers, you can use a method called prime factorization or a simpler approach involving multiples. We can also use the Greatest Common Divisor (GCD) to find the LCM.

#+begin_example
LCM(a, b) = (a * b) / GCD(a, b)
#+end_example

Example: Find the LCM of 12 and 18 using their GCD.

Step 1: Find the GCD of 12 and 18.

- You can use methods like prime factorization or the Euclidean algorithm to find the GCD.
- GCD(12, 18) = 6

Step 2: Use the formula to find the LCM.

#+begin_example
LCM(12, 18) = (12 * 18) / 6 = 216 / 6 = 36
#+end_example

So, the LCM of 12 and 18 is 36.

#+begin_src go
package main

import (
	"fmt"
	"strings"
	"time"

	"arjenwiersma.nl/aoc/internal/aoc"
)

func LCM(numbers []int) int {
	result := numbers[0]
	for i := 1; i < len(numbers); i++ {
		result = (result * numbers[i]) / GCD(result, numbers[i])
	}
	return result
}

func GCD(a, b int) int {
	if b == 0 {
		return a
	}
	return GCD(b, a%b)
}

func solve(s string, instr string, m map[string][]string, p2 bool) int {
	steps := 0
	for {
		d := 0
		if string(instr[steps%len(instr)]) == "R" {
			d = 1
		}

		if !p2 && s == "ZZZ" {
			break
		}
		if p2 && s[2] == 'Z' {
			break
		}

		s = m[s][d]

		steps += 1
	}
	return steps
}
func main() {
	content := aoc.AsLines("2023/Day08/input.txt")

	instr := content[0]
	m := make(map[string][]string)

	for _, v := range content[2:] {
		n := strings.Split(v, " = ")
		lr := strings.Split(n[1], ",")

		m[n[0]] = []string{strings.TrimSpace(lr[0][1:]), strings.TrimSpace(lr[1][:len(lr[1])-1])}
	}

	startTime := time.Now()

	steps := solve("AAA", instr, m, false)

	endTime := time.Now()
	elapsed := endTime.Sub(startTime)
	fmt.Printf("Part 1: %d (%v)\n", steps, elapsed)

	startTime = time.Now()

	var solves []int
	for k := range m {
		if k[2] == 'A' {
			solves = append(solves, solve(k, instr, m, true))
		}
	}

	// do stuff
	endTime = time.Now()
	elapsed = endTime.Sub(startTime)
	fmt.Printf("Part 2: %d (%v)\n", LCM(solves), elapsed)
}

#+end_src

* DONE Advent of Code 2023 day 9
CLOSED: [2023-12-09 za 07:29]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2023-day-9
:END:

The weekend generally is a place to find hard puzzles again, this time not so much. A simple quest to find the next number in a sequence with a fully written out algorithm to follow. They key here is to use recursion.

#+begin_src go
package main

import (
	"fmt"
	"time"

	"arjenwiersma.nl/aoc/internal/aoc"
)

func NextStep(in []int) int {
	allZero := true

	for _, v := range in {
		if v != 0 {
			allZero = false
		}
	}

	if allZero {
		return 0
	}

	var diffs []int
	for i := 1; i < len(in); i++ {
		diffs = append(diffs, in[i]-in[i-1])
	}

	p := NextStep(diffs)
	return in[len(in)-1] + p
}

func main() {
	content := aoc.AsLines("2023/Day09/input.txt")

	var lines [][]int
	for _, v := range content {
		lines = append(lines, aoc.AsNumbers(v))
	}

	startTime := time.Now()

	var res []int
	for _, v := range lines {
		res = append(res, NextStep(v))
	}

	r := aoc.SumArray(res)
	endTime := time.Now()
	elapsed := endTime.Sub(startTime)
	fmt.Printf("Part 1: %d (%v)\n", r, elapsed)

	startTime = time.Now()

	for _, v := range lines {
		aoc.Reverse(v)
	}

	res = []int{}
	for _, v := range lines {
		res = append(res, NextStep(v))
	}

	r = aoc.SumArray(res)
	endTime = time.Now()
	elapsed = endTime.Sub(startTime)
	fmt.Printf("Part 2: %d (%v)\n", r, elapsed)
}
#+end_src

* DONE Heading to the finish line
CLOSED: [2024-02-17 za 20:59]
:PROPERTIES:
:EXPORT_FILE_NAME: ou-heading-to-the-finish-line
:END:

It has been a little while. I have been swamped with work and the work on my thesis, leaving no room to finish the Advent of Code or much of anything else.

Yesterday I gave my practice presentation for my thesis. This means I am one more step closer to the finish line. During the day there were many interactions with fellow students. One of the topics has been the templates to use at Open Universiteit. So, I thought I would just create a repository of the templates that I use, so that anyone can learn from them.

The repository is here: [[https://github.com/credmp/ou-templates][https://github.com/credmp/ou-templates]]

* DONE My computing environment                  :@writing:emacs:development:
CLOSED: [2024-02-18 zo 15:35]
:PROPERTIES:
:EXPORT_FILE_NAME: my-computing-environment
:END:

#+begin_quote
This is a longer form article. I is relevant as of *February 18th 2023*. If the circumstances of my environment changes I will try to update this article to reflect the situation. You can find the full source code of my dotfiles on [[https://github.com/credmp/nixos-dotfiles/][Github]].
#+end_quote

I like consistency and simplicity. I do not like to use many different tools to do different things, I rather spend my time learning to use a few tools very well then to follow the hype on the latest trend of tools for something we have been doing forever.

This philosophy I transfer to pretty much everything in life. I have been using the same laptop bag for ages, I have a small mechanical keyboard, and I run the same version of my OS on all my devices. One device for on the go, the other for at home. They look the same and act the same, courtesy of an Linux distribution called [[https://nixos.org/][NixOS]].

Below you will find 2 screenshots, one from my laptop, the other from my desktop. The only difference is the size of the screen.

#+CAPTION: My Linux desktop on my laptop
#+NAME: fig:desktop
[[./images/desktop.png]]
#+CAPTION: My Linux desktop on my desktop
#+NAME: fig:desktop-large
[[./images/desktop-large.png]]

** NixOS

I use the NixOS distribution of Linux. NixOS is a wonderful operating system that works by declaring what you want your environment to be and then applying that declaration to the current version of the environment. That sounds difficult, but let me explain.

Suppose you have just installed a Linux distribution and you want to install the wonderful Emacs editor. In most distributions you will go to the package manager, search for Emacs and click on install. A few seconds later, Emacs is installed. With NixOS you edit a file that /describes/ your environment, you will add a line to it saying that Emacs is part of your environment. When you have saved the file you will ask NixOS to create a new version of your environment, to do so it will install Emacs for you.

I say it will create a new version of your environment. This means there is an old version as well, right? Yes! NixOS has a concept of Generations. This means every change happens in its own version of the environment. So, if a change goes wrong, you just revert back to the previous version.

This sounds like a great deal of work, and it is. It is not for the new Linux user, that is for sure. If you spend some time learning NixOS I am sure you will be grateful for it. Just the other day I tried to use the /wayland/ system on Linux, my configuration went horribly wrong and I was left with an unusable system. I rebooted the machine, selected the previous generation, and I was back where I started before the change. It is that useful!

As I share my configuration over multiple machines I split up the configuration into a machine specific version to my desktop, laptop, and the things that should run on both:

- [[https://github.com/credmp/nixos-dotfiles/blob/a7eca01bb7a091fef0f0b76276917f081d1161ea/.config/nix/configuration-desktop.nix][Desktop Configuration]]
- [[https://github.com/credmp/nixos-dotfiles/blob/a7eca01bb7a091fef0f0b76276917f081d1161ea/.config/nix/configuration.nix][Laptop Configuration]]
- [[https://github.com/credmp/nixos-dotfiles/blob/a7eca01bb7a091fef0f0b76276917f081d1161ea/.config/nix/shared.nix][Shared Configuration]]

The shared configuration contains all the juice, it sets up the graphical user interface, creates users and assigns to groups. This means that when you run this configuration you will end up in a very barren [[https://i3wm.org/][i3]] tiling window manager. More on that later.

Most of my applications are courtesy of something called [[https://github.com/nix-community/home-manager][home-manager]]. This is a user-space application that allows for easy changes to the environment. As none of these changes can actually wreck the environment I kept them outside of the default NixOS configuration.

My [[https://github.com/credmp/nixos-dotfiles/blob/a7eca01bb7a091fef0f0b76276917f081d1161ea/.config/home-manager/home.nix][home-manager configuration]] takes care of installing all the user-space tools that I use. It also sets up my shell and configures the Emacs daemon.

You might wonder, do you create a configuration file every time you need a tool? No! When I just need a one-off tool I use something called =nix-shell=. In the screenshots above you will notice that I run =neo-fetch=. This program is not part of my normal system as I only use it for screenshots as the one above. Within a terminal I run it as follows: =nix-shell -p neofetch --run neofetch=. This will temporarily install =neo-fetch= and run it. Afterwards it can be cleaned up. I also do this for most of the tools, such as =unzip=. I only install then when I need them. This keeps everything that is installed very clean.

You might also notice that there are not programming language toolchains in my configuration. That is correct. When I have a programming project I use something called =direnv=, see the [[https://direnv.net/][direnv webpage]] for some background.

Whenever I start a new programming project I run the following command in the project root: =nix --extra-experimental-features "nix-command flakes" flake new -t github:nix-community/nix-direnv .=. This will create a =flake.nix= file in which I can declare what this project needs as dependencies. As the rest of my environment is extremely clean, I will need to specify precisely what is needed. Take the listing below, it is part of a programming project in which I use Rust, Golang, Python and Java. Whenever I move into this project, all the tools will be installed. This also means that it works exactly the same on every single system where I use this setup.

#+CAPTION: A nix-direnv declaration for a polyglot programming project
#+name: lst:direnv
#+begin_src nix
{
  description = "A basic flake with a shell";
  inputs.nixpkgs.url = "github:NixOS/nixpkgs/nixpkgs-unstable";
  inputs.flake-utils.url = "github:numtide/flake-utils";

  outputs = { self, nixpkgs, flake-utils }:
    flake-utils.lib.eachDefaultSystem (system: let
      pkgs = nixpkgs.legacyPackages.${system};
    in {
      devShells.default = pkgs.mkShell {
        packages = with pkgs; [
          pkg-config
          openssl.dev
          cargo
          rustc
          rustfmt
          clippy
          rust-analyzer
          aoc-cli
          go
          gopls
          gotools
          govulncheck
          pkgs.jdk
          pkgs.jdt-language-server
          pkgs.python311
        ];
        # Environment variable specifying the plugin directory of
        # the language server 'jdtls'.
        JDTLS_PATH = "${pkgs.jdt-language-server}/share/java";
      };
    });
} 
#+end_src

This might seem like a hassle. It is true, it is more work then just installing Golang on Ubuntu and /"just having it"/. But once you use multiple systems or work together in groups you will start appreciating it, trust me.

** i3

As I like simplicity I tend to not use elaborate windowing environments, such as Gnome or KDE. I try them out every once in a while, but I also go back to i3. Back in the day I ran enlightenment, but now I have been using i3 WM for quite some years. My configuration is quite mature and I generally only change it when I want to add a new tool to my daily use, or when tools get good updates such as [[https://github.com/polybar/polybar][polybar]]. The configuration is part of my [[https://github.com/credmp/nixos-dotfiles/blob/a7eca01bb7a091fef0f0b76276917f081d1161ea/.config/i3/config][dotfiles]].

When I boot my system all I have is a top bar that contains the following information:

- 💻 Active workspaces (each has its own icon and use)
- 💾 Current fill state of my disks
- 🛡️ VPN status
- 🔊 Sound and its volume percentage
- 🛜 Wifi state (laptop only)
- 🔋 Battery state (laptop only)
- ⏰ Time
- 📥 Tray icons (flameshot, bluetooth and nextcloud)

That is it. After all those years working with computers, that is all I really need. If I could I would write a toggle for the bar as well, to only show up when needed.
The very appealing thing about i3 is its tiling feature. I will never have windows that overlap. Everything is neatly ordered in workspaces and within workspaces in columns or rows. As I create dedicated workspaces everything has a specific place:

1. Terminal ([[https://alacritty.org/][alacritty]] with [[https://github.com/tmux/tmux][tmux]])
2. [[/posts/22-years-of-emacs/][Emacs]]
3. Virtual Machines
4. Firefox
5. Chrome

From workspace 6 on I consider them "throw-away" workspaces. The things I will store there will be used only shortly. The exception is workspace 10 (or 0). This contains my Spotify.

To launch applications I use something called [[https://github.com/davatorium/rofi][Rofi]]. It is a window switcher, application launcher and menu replacement tool. It is very easy to customize and you can make it exactly what you want. My configuration is [[https://github.com/credmp/nixos-dotfiles/blob/a7eca01bb7a091fef0f0b76276917f081d1161ea/.config/rofi/config.rasi][available on github]]. 

#+CAPTION: Rofi launching applications in i3
[[./images/rofi.png]]

You can configure your environment exactly as you want. Take a look at [[https://www.reddit.com/r/unixporn/][r/unixporn]] for some more extreme versions of customized desktops.

* DONE Microsoft Teams (v2) on Linux
CLOSED: [2024-04-01 ma 10:29]
:PROPERTIES:
:EXPORT_FILE_NAME: ms-teams-on-linux
:END:

This post is just a small note for those of you who also run Microsoft Teams on Linux through their browser and now receive a note "your browser does not meet the requirements for the new Teams". It turns out that the client is looking at the user-agent string to determine which browsers it accepts, and which not.

So, if you have the message, install an user-agent switcher and select a common browser on a common OS (from the MS perspective) and you will suddenly meet the requirements.

* DONE The cyber cafe podcast
CLOSED: [2024-04-09 di 20:39]
:PROPERTIES:
:EXPORT_FILE_NAME: cyber-cafe-podcast
:END:

Last week I was a guest on the Cyber Cafe podcast by [[https://rootsec.nl/][rootsec]]. It was a fun discussion on education and the current xz backdoor story. It is in the Dutch language. It is available on youtube and included below:

#+HTML: <iframe width="560" height="315" src="https://www.youtube.com/embed/at2S1aP6p6E?si=NI9s0wz6JWfuHIAD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

* DONE Resigning as Hack The Box Ambassador
CLOSED: [2024-05-28 di 22:50]
:PROPERTIES:
:EXPORT_FILE_NAME: resigning-as-htb-ambassador
:END:

So, today I have some news. I will be resigning as Ambassador for Hack The Box after our in-person meetup in June (2024). This means that I will be stepping down from organizing the monthly virtual and quarterly in-person Hack The Box meetups. Let me explain how I got to this decision.

** The beginning

So, in 2019, I started out building a cyber security curriculum for [[https://www.novi.nl][NOVI Hogeschool]]. I had the ability to greenfield the courses and create something that is of value to students. In this curriculum I started using Hack The Box for exercises and training next to the regular classwork.

As more and more of my students went through the program I thought it would be cool to get together with the community in a meetup. I contacted Hack The Box and after a little work, the Hack The Box NL meetup was born. This was end of February 2020, and we were aiming for our first meetup in April of 2020. As you all know, the world changed in those days and our plans went into the dumpster. Instead we started hosting a monthly online meetup.

Only when our meetup turned 2 were we able to have our first in-person event. For me and my co-hosts it was a great learning experience to understand how to successfully organize an in-person event, from WiFi to the amount of pizza's that a group of hungry cyber-nerds will consume. For the first event we had our great friends from Hack The Box come over and join us. Check out this after-movie to get a sense of the scale and spot my "psycho"-face somewhere in the video.

#+HTML: <center><iframe width="560" height="315" src="https://www.youtube.com/embed/W11E2ISF-8E?si=W4L5YNKvViiXKTuh" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></center>

** The community

Since the early days the community has grown so rapidly. At the time of the blog post we are well past the 1800 members and we are growing to 1900! Of course these are not all people that show up at every meetup, but they come and go. Generally an in-peron meetup will have somewhere between 50 and 100 people attending. Our online meetups will have about 30 to 50 people RSVP-ing to join.

#+CAPTION: Christmas meetups require a "foute" christmas sweater
[[./images/meetup-christmas-scaled.jpg]]

The community is full of regulars, people that only swing by for the in-person meetups, and people that just try to figure out if cyber security is a fit for them. I loved meeting every single one of you all. It was such an experience to see friendships grow, skill-sets expand and people step up to actually present in front of a crowd.

** Making Friends

The very first person to ever log into the meetup was @GevuldCookie. She entered the zoom call when I was anxiously waiting for somebody to actually show up. In the same first meetup @DutchPyro joined and after some chatting and exchanging ideas we have been organizing the discord and meetups together ever since. A few years in and @Salp joined as a co-organizer.

Earlier this year we even had our first meetup-baby being born. How special is that?

As the meetup has been online most of the time I have made friends all over the globe, from Egypt to India, from South Africa to Ottowa. It has been quite extraordinary. Charles, from the Texas meetup, dropped by in Utrecht while on holiday in Europe. I went to Lissabon and met up with Pedro and we became such good friends.

#+CAPTION: Meeting up with Pedro in Portugal
[[./images/pedro.jpg]]

The list of people that have meant something to me and the meetup is extremely long, from Hack The Box we have had Soti, Kristi, Stella, Emma, Austin, Shaun, Bran and so many more. We also have had a quite large regular group of people joining every month. I started listing names here, but that entire list would be so long and I would certainly forget specific people. So just know that if you were a regular I loved the time that I spent with you!

** The cost of a meetup

As a meetup we were extremely lucky that NOVI flipped the bill for our in-person events. Imagine ordering 40 to 60 pizza's at your favorite place....  But the cost of organizing is much greater then just that, the amount of personal time that I have spent working on getting the meetups together, chasing down guests and getting things organized is quite something and this is exactly the point where it breaks for me.

After more then 4 years constantly worrying and working on the meetup, even planning my own family life around the meetups (I kid you not, we planned our family holidays so that they did not conflict with the meetups), it has been enough.

Being so involved has taken the joy out of Hack The Box for me, a price I have gladly paid, but a joy which I would like to get back. So for me that means stepping back, letting other people pick up a great meetup and giving it a bright new future.

** The end

Every beginning must have an end, and an end makes way to new beginnings. So does this step. Yes, the Hack The Box meetups are over for me after the June meetup, but with [[https://www.novi.nl][NOVI]] I will continue working for our community. I will continue being involved in the Hack The Box community in various ways, just not organizing monthly meetups.

We (NOVI) already host a *weekly hacking session* on Friday morning where we tackle Hack The Box machines and other types of challenges. Besides that we organize many different types of workshops and events across the areas of our curriculum (cyber security, development and business).

In the next year we will be *hosting a quarterly event* dedicated to security in a broader sense, and crossing over to the development realm. These events will line up with our starting moments in the school year. You can stay in the loop by registering on our meetup (https://www.meetup.com/workshops-novi-hogeschool/) page or follow me on LinkedIn (https://www.linkedin.com/in/credmp/).

As I am stepping back from my work on the Dutch Hack The Box meetup I am looking forward to exploring new events and opportunities to teach people about this wonderful field.

* DONE Master of Puppets^HScience!
CLOSED: [2024-06-24 ma 21:47]
:PROPERTIES:
:EXPORT_FILE_NAME: master-of-science
:END:

So, on Thursday I defended my thesis in front of the graduation committee, and passed! This means that the work I have been doing for the last year comes to an end. From now on there are not long nights and weekends working on my thesis anymore.

Back in 2021 I started my journey of achieving a Master's degree, first with a connecting program and then with the 2 year Master program. Even though I have been in computer science in some form for the last 30 years I still found it to be quite a learning experience.

I greatly enjoyed the track on formal verification of systems and found logic quite enjoyable to work with. My least favorite topic was the security course, mainly due to its reliance on a lot of relatively old literature, but that is only a small "unhappiness". The courses were well structured and very do-able in the time given.

So happy to be free of the work now. Here is to picking up some fun things again!

* DONE Tijd vinden om te studeren [Dutch article] :@writing:learn_to_study:
CLOSED: [2024-07-15 ma 23:05]
:PROPERTIES:
:EXPORT_FILE_NAME: leren-studeren-tijd-vinden
:END:

This is a Dutch artcile, there is also an [[/posts/learn-to-stud-finding-time][English version]].

Dus, jij hebt besloten om te gaan studeren? Misschien wil je jouw HBO- of Masterdiploma halen, of juist dat ene supertechnische certificaat bemachtigen. Het is geweldig dat je deze stap gaat zetten, maar zodra je begint, zul je vrij snel de vraag moeten beantwoorden waar je de tijd vandaan haalt.

Tijd is onze meest waardevolle, niet-hernieuwbare bron. Studeren vergt tijd – en niet zo'n klein beetje ook – dus wil je het natuurlijk goed doen. De meeste studies verwachten dat je wekelijks ergens tussen de 12 en 24 uur investeert om bij te blijven, en dat is flink wat! Als je nog niet studeert, probeer dan eens na te denken over welke dagen en momenten je die tijd kunt vrijmaken. Ga je minder uit eten of juist minder sporten? Vroeg opstaan in het weekend, of juist extra laat naar bed?

De meeste studenten lopen tegen dit probleem aan wanneer ze beginnen met studeren; ik zie het maar al te vaak. Je start vol vertrouwen aan een studie, maar dan realiseer je je dat je niet hebt nagedacht over hoe het in jouw leven past en wat je moet opofferen om te kunnen studeren. Veel studenten proberen dan ook alles tegelijk te doen, met alle gevolgen van dien. Gelukkig is er een strategie die je kunt toepassen. Ik heb deze strategie zelf gebruikt tijdens mijn deeltijd HBO- en Masterstudies, en voor mij werkte het perfect.

De kern van de strategie is het gebruik van je agenda. Om goed de baas te zijn over je tijd, moet je precies weten wanneer je wat gaat doen. Dit klinkt eenvoudig, maar de meeste mensen noteren alleen belangrijke zaken in hun agenda, zoals de tandartsafspraak of de verjaardag van tante Loes.

Op een dag doe je natuurlijk heel veel. Zelf heb ik een baan van 40 uur per week, ga ik naar de sportschool, wil ik tijd doorbrengen met mijn gezin, en nog veel meer. Als ik die activiteiten niet zou inplannen, raak ik al snel het overzicht kwijt. Zonder overzicht wordt het ook moeilijk om effectief te studeren, want dan staat opeens tante Loes op de stoep.

De strategie omvat de volgende stappen:

1. Gebruik een kalender die je overal kunt raadplegen.
2. Blokkeer je werktijd en houd je hieraan.
3. Blokkeer ook tijd voor je gezin en vrienden.
4. Plan studiemomenten in.

Het maakt niet echt uit welke kalender je gebruikt, zolang deze maar voor jou beschikbaar is. In mijn voorbeelden zal ik de Proton Calendar gebruiken, die is lekker veilig en gevestigd in de EU. Zo heb je geen last van grote techbedrijven die meekijken in jouw planning.

Een lege kalender ziet er zo uit.

#+CAPTION: Een lege agenda, dat is nog eens rustig!
[[./images/_20240715_193929screenshot.png]]

Zoals je kunt zien, heb ik elk gebied van mijn leven een eigen kleurtje gegeven. Dat is superhandig, want daarmee zie je in één oogopslag waar een afspraak bij hoort.

#+CAPTION: Elke kalender een eigen kleur, helaas ben ik niet goed in kleuren kiezen.
[[./images/_20240715_194152screenshot.png]]

Als eerste stap plannen we de werkdagen in. Ik heb zelf al mijn werkafspraken in mijn agenda staan, maar ook dan blokkeer ik mijn werktijd met een kalenderafspraak. Op die manier weet ik altijd wanneer ik wel of niet beschikbaar ben op een gegeven tijdstip. Als je ook moet reizen naar en van je werk, plan dan ook die tijd in. Ik doe dat bijvoorbeeld op woensdag en vrijdag.

#+CAPTION: Stap 1, plan jouw werkdagen in
[[./images/_20240715_195048screenshot.png]]

Dit lijkt misschien een beetje suf, want je weet toch dat je werkt? Natuurlijk is dat zo, maar voor het mentale model van jouw beschikbare tijd is het belangrijk om deze periode te blokkeren. Zo weet je zeker dat je die tijd niet kunt gebruiken om te studeren. En kijk, nu lijkt het alsof er nog heel veel tijd over is, toch?

Tijdens mijn studie vond ik het ook belangrijk om tijd te reserveren voor mijn gezin en om leuke dingen te doen. Studeren moet leuk zijn en mag niet aanvoelen als een straf waardoor je geen plezierige activiteiten meer kunt ondernemen. Laten we nu alle tijd voor gezin en vrienden ook in de kalender zetten.

#+CAPTION: Stap 2, tijd voor het gezin en vrienden
[[./images/_20240715_195810screenshot.png]]

Dan wordt het al een ander verhaal. Voor mij was het weekend belangrijk. Iedereen werkt hard gedurende de week, dus er is ook tijd nodig waarin we allemaal kunnen ontspannen. Wat meteen opvalt, is dat er dan relatief weinig tijd over lijkt te zijn om te studeren, maar schijn bedriegt. Ik vond het heel fijn om 's avonds te studeren, zo ongeveer van 8 uur tot 12 uur. Dat zijn toch 4 uren op een dag die voor mij goed werkten. Laten we die tijd inplannen.

#+CAPTION: Stap 3, tijd om te studeren
[[./images/_20240715_200322screenshot.png]]

Dat zijn 4 blokken van 4 uur, plus de zaterdagochtend van 3 uurtjes — in totaal 19 uur die beschikbaar zijn om te studeren. Tijdens het inplannen viel meteen op dat de sportsessie op donderdag niet handig uitkwam, dus die heb ik verplaatst naar de ochtend. Met al deze ingeplande studietijd blijft er ook ruimte over voor familie en vrienden, precies op die momenten dat het voor iedereen goed uitkomt.

Wat nu als je geen avondmens bent? Ik begeleid ook studenten tijdens hun afstudeertraject, en sommigen zijn meer een ochtendmens. Zij staan om 5 uur 's ochtends op en studeren tot 7 uur. Dit doen ze vaak omdat ze kleine kinderen hebben en niet willen dat hun partner met alle zorg achterblijft. Zelf geef ik de voorkeur aan de avond, maar goed, ieder zijn ding.

Wanneer het nodig is, bijvoorbeeld als je dicht bij een deadline zit, kun je natuurlijk altijd tijd van een ander blok gebruiken. Doe dat echter altijd in overleg. Het voordeel van alles uitplannen is dat het duidelijkheid schept, maar daardoor ontstaan ook verwachtingen. Als je dan iets verandert, ook al is het tijdelijk, leg het uit zodat je geen problemen krijgt. Ik paste mijn schema vaak aan door naar de studielast van een module te kijken en een studieplan te maken; daarover zal ik later meer schrijven.

Zelf had ik ook nog bonustijd in mijn schema. De zondagochtend was vaak beschikbaar, afhankelijk van hoe mijn zoon naar een bouldersessie keek. Daarnaast had ik 's ochtends vaak nog een uurtje tijd, tussen het moment dat iedereen naar werk en school gaat en dat ik daadwerkelijk aan mijn werk begin. Die tijd gebruikte ik om papers te lezen en mijn eerste aantekeningen te maken. Maar ook daarover zal ik later meer schrijven.

Het "goed" gebruiken van de kalender om tijd te reserveren is natuurlijk niet revolutionair. Er zijn ook andere methoden zoals de [[https://www.youtube.com/watch?v=6o2tm00Ar8A]["Trident Method" (uitgelegd door Ali Abdaal)]], en talloze andere technieken om tijd goed in te delen. Maar dit is de methode die voor mij goed werkte.

Hopelijk begin je jouw studietijd nu met een goed systeem om je tijd in te delen. Dit is de eerste stap naar een succesvolle studietijd!

* DONE Finding time to study :@writing:learn_to_study:
CLOSED: [2024-07-15 ma 23:05]
:PROPERTIES:
:EXPORT_FILE_NAME: learn-to-stud-finding-time
:END:

This is an English article, there is also a [[/posts/leren-studeren-tijd-vinden][Dutch version]].

So, you've decided to start studying? Maybe you want to earn your Bachelor or Master's degree, or perhaps you're aiming for that highly technical certificate. It's great that you're taking this step, but once you begin, you'll quickly need to answer the question of where you'll find the time.

Time is our most valuable, non-renewable resource. Studying requires time – and not just a little – so you naturally want to use it well. Most programs expect you to invest between 12 and 24 hours per week to keep up, and that's quite a bit! If you're not currently studying, try thinking about which days and times you could free up that time. Will you eat out less or exercise less? Get up early on weekends or stay up late?

Most students run into this problem when they start studying; I've seen it all too often. You start your studies with full confidence, only to realize you haven't considered how it fits into your life and what you need to sacrifice to make it work. Many students try to do everything at once, with predictable results. Thankfully, there is a strategy you can apply. I used this strategy during my part-time Bachelor and Master's studies, and it worked perfectly for me.

The core of the strategy is using your calendar. To manage your time effectively, you need to know exactly when you'll do what. This sounds simple, but most people only note important things in their calendar, like dentist appointments or Aunt Loes's birthday.

You do a lot in a day. Personally, I have a 40-hour workweek, go to the gym, spend time with my family, and much more. If I didn't plan these activities, I'd quickly lose track. Without an overview, it becomes difficult to study effectively because suddenly Aunt Loes will show up at the door.

The strategy includes the following steps:

1. Use a calendar that you can access anywhere.
2. Block out your work hours and stick to them.
3. Also block time for your family and friends.
4. Schedule study sessions.

It doesn't really matter which calendar you use, as long as it's accessible to you. In my examples, I'll use the Proton Calendar because it's secure and based in the EU. This way, you don't have to worry about big tech companies snooping into your schedule.

An empty calendar looks like this:

#+CAPTION: An empty calendar, that's quite calm!
[[./images/_20240715_193929screenshot.png]]

As you can see, I've given each area of my life its own color. This is super handy because you can immediately see which appointment belongs to which area.

#+CAPTION: Each calendar its own color, though I'm not great at choosing colors.
[[./images/_20240715_194152screenshot.png]]

As the first step, let's plan the workdays. I already have all my work appointments in my calendar, but I also block my work time with a calendar event. This way, I always know when I am or am not available. If you also have to travel to and from work, plan that time as well. I do this on Wednesdays and Fridays.

#+CAPTION: Step 1, plan your workdays
[[./images/_20240715_195048screenshot.png]]

This may seem a bit silly because you know you're working, right? Of course, but for the mental model of your available time, it's essential to block this period. This way, you know you can't use that time for studying. See, now it seems like there's still a lot of time left, right?

During my study, I also found it important to reserve time for my family and to do fun things. Studying should be enjoyable and not feel like a punishment that prevents you from doing pleasant activities. Let’s now add all the family and friends' time to the calendar.

#+CAPTION: Step 2, time for family and friends
[[./images/_20240715_195810screenshot.png]]

Now it's a different story. Weekends were important for me. Everyone works hard during the week, so time is needed to relax together. What's immediately noticeable is that there seems to be relatively little time left for studying, but appearances can be deceiving. I found it very convenient to study in the evenings, from around 8 PM to 12 AM. That's 4 hours in a day that worked well for me. Let's schedule that time.

#+CAPTION: Step 3, time to study
[[./images/_20240715_200322screenshot.png]]

That amounts to 4 blocks of 4 hours, plus 3 hours on Saturday morning — totaling 19 hours available for studying. While planning, it immediately became apparent that the workout session on Thursday didn't fit well, so I moved it to the morning. With all this scheduled study time, there's also room for family and friends, at times that are often convenient for everyone.

But what if you're not a night owl? I also guide students during their graduation projects, and some are more morning people. They get up at 5 AM and study until 7 AM, often because they have small children and don't want to leave their partner with all the care. Personally, I prefer the evening, but to each their own.

When necessary, such as when a deadline is approaching, you can always borrow time from another block, but always do this in consultation. The advantage of planning everything is that it provides clarity, but it also creates expectations. If you change something, even temporarily, explain it, so you don't run into problems. I often adjusted my schedule by looking at the workload of a module and creating a study plan; I'll write more about that later.

I also had bonus time in my schedule. Sunday morning was often available, depending on my son's interest in a bouldering session. Additionally, I often had an hour in the morning, between when everyone left for work and school and when I started working. I used that time to read papers and make my initial notes. But more on that later.

Using the calendar effectively to reserve time is not revolutionary. There are other methods such as the ["Trident Method" (explained by Ali Abdaal)](https://www.youtube.com/watch?v=6o2tm00Ar8A), and many other techniques for good time management. But this is the method that worked well for me.

Hopefully, you'll start your study time now with a good system to manage your time. This is the first step towards a successful study period!

* DONE "Deep Work" voor het studeren [NL] :learn_to_study:
CLOSED: [2024-08-21 wo 22:52]
:PROPERTIES:
:EXPORT_FILE_NAME: learn-to-stud-deepwork
:END:

[[./images/learn-to-study-deepwork/_20240720_225806screenshot.png]]

In [[/posts/leren-studeren-tijd-vinden/][mijn vorige artikel]] heb ik uitgelegd hoe je tijd kunt vinden om te studeren, de vraag is echter, is alle tijd hetzelfde? Het simpele antwoord is "nee". Maar waarom niet, zul je vragen, en daarmee komen we op het onderwerp van dit artikel.

Cal Newport heeft een fantastisch boek geschreven, "[[https://www.bol.com/nl/nl/p/deep-work/9200000047340481/?bltgh=ujEmm8L1hL083Qs4-KJKSQ.2_18.19.ProductTitle][Deep Work: Rules for Focused Success in a Distracted World]]". In dit boek onderzoekt hij hoe je gefocust werkt en wat er voor nodig is om gefocust te blijven [1]. In het boek identificeert hij 2 soorten werk; "Deep Work" en "Shallow Work". Deze concepten hebben voor mij de aanpak van mijn dagelijkse werk zelfs veranderd, maar dat is een verhaal voor een andere keer.

** Deep work vs Shallow work

Deep Work is feitelijk het werk waarbij je volledige aandacht (concentratie) nodig is, bijvoorbeeld het lezen van een ingewikkeld stuk theorie in een paper of een boek, of het programmeren van een algoritme voor een lesopdracht. Het gaat hier dus om het type werk waarbij een afleiding zorgt dat je helemaal kwijt raakt waar je was gebleven en afleiding dus zeer ongewenst is.

Shallow Work, daarentegen, is het werk waarvoor je maar weinig focus nodig hebt. Denk bijvoorbeeld aan je email bijwerken, of met medestudenten overleggen. In essentie, werk waarbij je even afgeleid kan worden en meteen weer verder kan gaan.

Een studie, net als een werkomgeving, heeft een combinatie van Deep Work en Shallow Work. Dit feit kun je gebruiken om jouw tijd nog beter in te delen.

** Tijd blokkeren

In mijn vorige artikel hebben we blokken van ongeveer 4 uren kunnen reserveren in de kalender. Dit is niet per toeval. Cal Newport beschreef dat geoefende "Deep Workers" in staat zijn om maximaal 3 uren achterelkaar in volle focus te werken. Dat betekent 3 uurtjes werken aan een paper of opdracht, en dan is het wel klaar. Je hersenen hebben er dan ook even genoeg van. Om die 3 uren gefocust te werken heb je wel oefening nodig. Als je nog nooit zo lang aan iets hebt gezeten, dan moet je eerst je hersenen trainen. Dit doe je door met een uurtje te beginnen en dan langzaam op te bouwen. Niet te snel, natuurlijk.

Newport identificeerde ook dat om gefocust te gaan werken de meeste mensen een ritueel ontwikkelen. Een soort mentaal stappenplan om je hersenen zover te krijgen dat je er even echt voor kan gaan zitten. Hij beschrijft de rituelen van grote denkers uit het verleden, maar in dit artikel zal ik mijn strategie uitleggen. Het is zeer de moeite waard om de verschillende strategieën in zijn boek te onderzoeken.

** Een ritueel om te focussen

Een techniek die ik veel inzet is om eerst Shallow Work tijd te reserveren om zoveel mogelijk de taken voor een week (of leerlijn) uit te schrijven en na te lezen. Simpelweg een todolijst is al meer dan voldoende. Op deze wijze hebben mijn hersenen niet de neiging om te gaan denken "zouden we iets vergeten?". Elke keer als ik ga zitten om te studeren neem ik eerst een periode van 10 tot 15 minuten om:

1. De todolijst na te lopen of het nog up-to-date is.
2. Alle middelen die ik nodig heb te verzamelen.
3. Mijn omgeving leeg te maken, alleen dat wat ik nodig heb mag er zijn.

De todolijst, in mijn geval een notitie waarin ik alle onderdelen van een leerlijn heb beschreven (welke boeken, papers, websites moet ik lezen? Wat is de eindopdracht?) en waarbij ik al mijn vragen in een eigen sectie zet. Deze vragen worden (als het goed is) gedurende de leerlijn beantwoord, en zo niet, dan heb ik op het einde iets om te vragen aan de docent.

Laat ik een voorbeeld geven. Voor de cursus "Software Quality Management" kreeg ik een waslijst aan artikelen om te lezen, echt een serieuze stapel. De artikelen hadden relatie op onderdelen van de lesstof en ik heb vervolgens voor mijzelf een planning gemaakt welk paper ik in welke week gelezen moest hebben (waar ze relevant waren voor het lesonderwerp). Ook heb ik ze gekoppeld aan onderdelen van de eindopdracht, zodat ik altijd een startpunt heb. Zo kun je natuurlijk alles van een leerlijn uitzoeken en uitstippelen, vaak is een syllabus of lesindeling hier heel handig als leidraad. Hieronder zie je daadwerkelijke screenshots van mijn "planning" voor de leerlijn.

#+CAPTION: Papers in een weekplanning
[[./images/learn-to-study-deepwork/_20240718_232022screenshot.png]]

#+CAPTION: Een simpele planning om bij te houden of ik op schema zit
[[./images/learn-to-study-deepwork/_20240718_235148screenshot.png]]

** Geen afleidingen

Als je voor jezelf alles op een rijtje hebt, dan kun je met een snelle review al vrij eenvoudig in een goede flow terecht komen. Ik zorg er daarna voor dat ik alles wat ik nodig heb op mijn bureau leg, of digitaal beschikbaar heb. Er is niets zo vervelends als beginnen en er dan achter te komen dat je iets in de mail moet opzoeken om dan afgeleid te worden door een gekke meme die door een medestudent is opgestuurd, weg is je studietijd.

#+CAPTION: Een opmerking waar je wel op moet reageren, toch?
[[./images/learn-to-study-deepwork/_20240720_232155screenshot.png]]

En dat is ook meteen het 3de punt. Alles leeg (of uit). Zet je telefoon op stil en "niet storen", alles wat notificaties op de computer kan maken afsluiten en de niet storen modus aanzetten. Soms vraagt dit thuis ook afspraken zoals "als de deur dicht is, niet storen". Dat is misschien gek, maar als je deeltijd studeert is een gemiste studiesessie al snel een beetje vertraging bij het afronden, en als het te vaak gebeurt dan loop je echt achter.

#+begin_tip
TIP: Voor je telefoon zijn apps zoals [[https://play.google.com/store/apps/details?id=cc.forestapp&hl=en_US][Forest]] echt ideaal. Je krijgt geen notificaties, en je kan niks met jouw telefoon. En voor elke sessie plant je weer boompjes in jouw digitale bos, hoe leuk is dat?
#+end_tip

Dit doe je allemaal in dat ene kwartiertje (of een uur afhankelijk van hoe duidelijk je al hebt wat je moet gaan doen), en dan is het tijd om echt aan de gang te gaan, je begint feitelijk aan jouw Deep Work sessie. Ik zet dan vaak nog een zacht achtergrond muziekje aan [[https://open.spotify.com/playlist/37i9dQZF1DWWQRwui0ExPn?si=79cc43e7aee74238][om complexe papers te lezen]] of [[https://open.spotify.com/playlist/67Jf1k8YK6Rkik3KmCkRay?si=ab552a98d2394727][code te schrijven]] en gaan maar.

Niet alle tijd is hetzelfde. Om effectief te studeren moet je het voor jezelf mogelijk maken om te concentreren. Zorg dat je al je vragen en zorgen hebt opgeschreven, dat er geen afleidingen zijn en dat alles wat je nodig hebt er gewoon al is. Bouw het tijdens jouw studie langzaam op, eerst sessie van een uur en dan op het einde echt knallen!

** Bronnen

[1] Newport (2016) Deep Work: Rules for Focused Success in a Distracted World, Grand Central Publishing.

* DONE Bronnen beheren met Zotero [NL]                     :learn_to_study:
CLOSED: [2024-09-03 di 19:22]
:PROPERTIES:
:EXPORT_FILE_NAME: learn-to-stud-zotero
:END:


[[./images/learn-to-study-zotero/_20240722_203307screenshot.png]]

Je hebt [[/posts/leren-studeren-tijd-vinden/][tijd gereserveerd om te gaan studeren]] en [[/posts/learn-to-stud-deepwork/][je volgt een ritueel om goed in jouw "Deep Work" modus te komen]], dat studeren gaat echt goed lukken! Tijdens de colleges en in de lesmaterialen vind je allerlei links naar papers, websites, YouTube videos en haal je veel informatie uit boeken. Al deze bronnen zijn zeer waardevol en bij de eindopdracht zul je veel van deze bronnen weer moeten gebruiken om argumenten te onderbouwen of juist iets te ontkrachten. Hoe ga je dan om met die bronnen zonder dat je gek wordt van allerlei documentjes?

Een natuurlijk reactie is om hiervan allemaal bladwijzers te maken in jouw browser als het op het web is, en voor andere bronnen juist weer in een bestandje bij te houden met wat je hebt gelezen. Dit gaat een tijdje goed, en dan begin je aan jouw opdracht.

Eerst kom je erachter dat je een of ander speciaal formaat moet gebruiken om naar bronnen te verwijzen, APA of IEEE, en dat je dus een lijst bijhoudt van de artikelen die je daadwerkelijk in de opdracht gebruikt. Er mogen geen bronnen in de lijst staan die je niet in de tekst gebruikt en in de tekst mag je niet verwijzen naar iets wat niet in de bronnenlijst staaat. Dan wordt het opeens lastig. Nu blijkt een programma zoals Word wel een bronnenbeheersysteem te hebben, maar dat is echt wel veel werk omdat het per document bronnen opslaat en op macOS werkt het zelfs [[https://answers.microsoft.com/en-us/msoffice/forum/all/apa-bibliography-not-sorted-alphabetically-for/803b684c-4f45-4b5c-82ec-8199cebe3bd9][niet naar behoren]]. Het systeem van bladwijzers en losse documentjes blijkt toch niet zo handig.

Wat werkt dan wel? Mijn advies is om [[https://www.zotero.org/][Zotero]] te gebruiken ([[https://alternativeto.net/software/zotero/][alternatieven]]). Het programma wordt omschreven als een research assistant. Het idee is dat je alle bronnen die je raadpleegt toevoegt aan Zotero. In Zotero administreer je wie de auteur is, sla je een korte omschrijving (abstract) van de bron op en geef je aan wanneer je de bron hebt geraadpleegd. In onderstaande screenshot zie je een (bijna) lege Zotero bibliotheek met enkel mijn vorige artikel als geraadpleegde bron. Aan de rechterkant zie je alle meta informatie over de bron.

#+CAPTION: Zotero met een artikel
[[./images/learn-to-study-zotero/Zotero-empty.png]]

Een hele gave feature van Zotero is dat het ook een snapshot van online bronnen bewaard. In dit geval heeft het een offline versie van mijn artikel gemaakt, precies zoals het eruit zag toen ik het opsloeg. Op deze wijze is altijd de bron beschikbaar, ook al haal ik mijn website morgen offline. Met PDF bronnen slaat het zelfs een kopietje van het bestand op. Super handig, en jij hebt altijd de informatie bij je die je nodig hebt.

#+CAPTION: Een snapshot in Zotero
[[./images/learn-to-study-zotero/Zotero-snapshot.png]]

Je kan een gratis Zotero account aanmaken als je de zekerheid van een goede backup wil hebben. Dat is optioneel, maar anders moet jij zorgen voor een goede backup van jouw database, dus het is zeker een aanrader. In mijn eigen Zotero staan duizenden papers en websites opgeslagen. Ik gebruik verschillende plugins waar ik later meer over ga schrijven. Met die plugins haal ik bronnen van het web, mijn telefoon en zorg ik voor goede notities over de bronnen.

Zotero heeft mij echt zoveel tijd gescheeld, en ik hoop dat jij hiermee ook een tool krijgt om net iets relaxter te gaan studeren.

* DONE Choose your tools :clojure:development:
CLOSED: [2024-09-30 ma 14:25]
:PROPERTIES:
:EXPORT_FILE_NAME: choose-your-tools
:END:

I ❤️ to build software. I sadly do not have a lot of time next to my daily work to spend on my side projects, so I have to be disciplined in where I invest time. I wish I could spend endless amounts of time on exploring new technologies, but sadly I simply do not have that time. In writing this is sometimes referred to as [[https://www.masterclass.com/articles/what-does-it-mean-to-kill-your-darlings]["to kill your darlings"]].

#+begin_quote
Sir Arthur Quiller-Couch wrote in his 1916 book On the Art of Writing: “If you here require a practical rule of me, I will present you with this: ‘Whenever you feel an impulse to perpetrate a piece of exceptionally fine writing, obey it—whole-heartedly—and delete it before sending your manuscript to press. Murder your darlings.’”
#+end_quote

Luckily for me, I just finished my latest round of education, so I now do have time to spend on building some of the ideas that have been floating around in my head for the last 3 years. And I did start out writing stuff. Some in ~Rust~, some in ~Go~ and others in ~Clojure~.

Like many programmers I love to explore new languages, I think you always learn something new from them. As Clojure really taught me about functional programming when all I knew was imperative languages. In the end, after having a summer of not working on my studies I have 0 projects completed, but I do have 4 versions of them.

So, I decided to step back and evaluate. I decided to kill my darlings of different programming languages and focus solely on Clojure again. Development in Clojure conforms to [[https://konmari.com/marie-kondo-rules-of-tidying-sparks-joy/][Rule 6]] for me. While working out the problem I love the interactive build method. I actually like the parentheses, I know... weirdo me 🤗.

You might even remember that I used to do [[https://www.youtube.com/@BuildFunThings][a live-streaming series]] in Clojure. I still don't have a lot of time to continue that one, but who knows... I might drop some videos later again.

Since the summer I have been somewhat involved in [[https://biffweb.com/][Biff]], a rapid prototyping web framework in Clojure. It provides a set of sensible defaults to just get started, and it allows you to easily change all its bits. I have been building my latest project on top of it, which, with a bit of luck, might even make it to production.

* DONE Enhance testability with selmer :clojure:development:
CLOSED: [2024-10-08 di 19:42]
:PROPERTIES:
:EXPORT_FILE_NAME: using-selmer
:END:

This is my first article in a series called *Rock Solid Software*. In it I explore different dimensions of software that does not simply break. You can write good software in any programming language, although some are more suited to a disciplined practice then others, Clojure is definitely in the /relaxed/ space of discipline here.

Today I am exploring the use of Selmer templates in Clojure. If you have explored [[https://www.biffweb.com][Biff]] at all you will know that all the UI logic works by sending ~Hiccup~ through a handler, which will turn into HTML through ~rum~ (specifically the ~wrap-render-rum~ middleware). If you provide a vector as a result for an endpoint, it will be converted to HTML.

#+begin_src clojure
;; You provide this...
[:h1 "test"]
;; => [:h1 "test"]

;; It will then be converted to HTML
(rum/render-static-markup
  [:h1 "test"])
;; => "<h1>test</h1>"
#+end_src

This is absolutely great for rapid prototyping, however it becomes quite tedious if you want to test it. The idea of testing a function is to provide it some /inputs/ and to validate if the /outputs/ match the expectation. Verifying if HTML matches an expectation, or a vector of hiccup for that matter, is quite difficult.

To increase testability I added [[https://github.com/yogthos/Selmer][selmer]] to my project. This separates presentation from data by having selmer render templates with a map of data. Selmer is based on Django templates, which means that it has a rich set of features, such as ~extending~ base templates, defining ~blocks~ and providing control structures such as ~if~ and ~for~ loops. A very simple template looks like this:

#+begin_src html
{% extends "_layout.html" %}

{% block content %}
<article>
Hallo <b>{{name}}</b> from simple template
</article>
{% endblock %}
#+end_src

As the template extends ~_layout.html~, lets take a look at that as well. I have stripped it down to the bare minimum here, but you might expect scripts, css, nav bars and many other things in the base template. The important thing here is that the ~block~ has the name of /content/, and our snippet above also has a ~block~ called /content/, the above ~article~ will be put inside the ~main~ below.

#+begin_src html
<!doctype html>
<html class="no-js" lang="">
  <head>
    <title>{{title}}</title>
  </head>
  <body>
    <main id="main">
      {% block content %}
      {% endblock %}
    </main>
  </body>
</html>
#+end_src

All that is left is to provide a ~middleware~ that will handle the selmer return type from an endpoint. In this case a map with a ~:template~ and ~:content~ key. If both keys are inside the response, the given template will be rendered using the content map. 

#+begin_src clojure
(defn wrap-render-selmer [handler]
  (fn [ctx]
    (let [response (handler ctx)]
      (if (and (map? response) (every? response [:template :content]))
        (let [res (selmer/render-file (:template response) (:content response))]
          {:status 200
           :headers {"content-type" "text/html"}
           :body res})
        response))))
#+end_src

My new authentication function has become quite simple, provide a login page using the ~auth/login.html~ template. Of course it requires a whole bunch of different attributes in order to render the whole page, but another wrapper adds all the required metadata known to the application already, such as ~css~ and ~script~ files, application settings and even theme information. All the endpoint has to take into account is its own required information.

#+begin_src clojure
(defn login [{:keys [params] :as ctx}]
  (let [err (:error params)]
    (ui/page ctx {:template "auth/login.html"
                  :content (merge {} (when err {:errors [err]}))})))
#+end_src

This is all great and all, but it has nothing to do with testability, right? Well, a map is easier tested then an unstructured vector, right? In other languages, such as Rust, you can get compile time validation of templates, which is great! Sadly selmer does not have that, however we can just simply render a template file and see if there are any missing values.

The below snippet takes the "missing" value and replaces it with a placeholder. So, given a template and an endpoint function we can easily check if all required entries are provided in the map. The below function renders the template, provides a ~csrf~ token which is not available inside testing, and verifies that the template does not have any missing values.

#+begin_src clojure
(defn missing-value-fn [tag _context-map]
  (str "<Missing value: " (or (:tag-value tag) (:tag-name tag)) ">"))

(selmer.util/set-missing-value-formatter! missing-value-fn)

;; Ensure all the page's required fields are present.
(deftest selmer-validation
  (let [s (sut/page {} {:template "_layout.html" :content {}})
        ;; CSRF is not set during testing...
        res (selmer.parser/render-file (:template s) (assoc (:content s) :csrf "csrf"))]
    (is (not (str/blank? res)))
    (is (not (str/includes? res "<Missing value:")))))
#+end_src

Another step into building rock solid software.

* DONE Using Traefik :development:
CLOSED: [2024-11-17 zo 12:18]
:PROPERTIES:
:EXPORT_FILE_NAME: setting-up-traefik
:END:

I recently came across [[https://traefik.io/traefik/][Traefik]]. It is a reverse proxy built specifically for services in the cloud. I was searching for a convenient (up-to-date) way to expose my project using a reverse proxy within ~docker-compose~. I used to use ~nginx~ for this, but it then requires a generator and an lets encrypt listener (so 3 containers). Traefik only requires a single container and allows you to label your docker containers to apply rules to them.

The below configuration creates a traefik instance, sets it up to host port 80 and 443 for web, and 8080 for its dashboard (protect that port in your firewall). It also sets up ~letsencrypt~ certificates and automatic redirection from port 80 to 443. 

#+begin_src dockerfile
version: '3'

services:
  reverse-proxy:
    image: traefik:v3.1
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik.yml:/traefik.yml:ro # Traefik config file
      - traefik-certs:/certs # Docker volume to store the acme file for the Certifactes

  app:
    image: your/image
    ports:
      - 8081:8080
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.app-http.rule=Host(`example.com`) || Host(`www.example.com`)"
      - "traefik.http.routers.app-http.entrypoints=web"
      - "traefik.http.routers.app-http.middlewares=redirect-to-https"
      - "traefik.http.routers.app-https.rule=Host(`example.com`) || Host(`www.example.com`)"
      - "traefik.http.routers.app-https.entrypoints=websecure"
      - "traefik.http.routers.app-https.tls=true"
      - "traefik.http.routers.app-https.tls.certresolver=letencrypt"
      - "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"
      - "traefik.http.middlewares.redirect-to-https.redirectscheme.permanent=true"
volumes:
  traefik-certs:
    name: traefik-certs
#+end_src

The mentioned config file is reproduced below:

#+begin_src
api:
  dashboard: true # Optional can be disabled
  insecure: true # Optional can be disabled
  debug: false # Optional can be Enabled if needed for troubleshooting 
entryPoints:
  web:
    address: ":80"
  websecure:
    address: ":443"
serversTransport:
  insecureSkipVerify: true
providers:
  docker:
    endpoint: "unix:///var/run/docker.sock"
    exposedByDefault: false
    network: proxy # Optional; Only use the "proxy" Docker network, even if containers are on multiple networks.
certificatesResolvers:
  letencrypt:
    acme:
      email: contact@example.com
      storage: /certs/acme.json
      #caServer: https://acme-v02.api.letsencrypt.org/directory # prod (default)
      caServer: https://acme-staging-v02.api.letsencrypt.org/directory # staging
      httpChallenge:
        entryPoint: web
#+end_src

* DONE Remembering Bastiaan
CLOSED: [2024-12-02 ma 18:41]
:PROPERTIES:
:EXPORT_FILE_NAME: remembering-bastiaan
:END:

Today the academic world is remembering [[https://cs.ou.nl/members/bastiaan/][Bastiaan Heeren]], who passed away last week.

I spent the better time of a year working on my thesis, and before that I enjoyed lectures given by Bastiaan. He was a person with a great love for teaching, especially when you can get into the nitty gritty details of software quality and the benefits of functional programming.

I look back fondly on my time with Bastiaan. He was an open, warm, critical and encouraging human being. He had a great love for his family and work. 

Right after [[/posts/master-of-science/][I graduated]] his illness progressed and as a result he was unable to join the graduation ceremony last September. We exchanged gratitude through email and in a blink of an eye, it is over. He was only 46.

You will be missed.

* DONE The right to repair
CLOSED: [2024-12-04 wo 22:13]
:PROPERTIES:
:EXPORT_FILE_NAME: ifixit-dell
:END:

My old laptop, now almost 6 years old, has seen it all. From conferences, to lectures, traveling to distant places and to the library. I did a lot of work on it during the writing of my thesis, and it is a victim to countless hours of compiler time.

Sadly the battery started to die. It got to the point that you can only use it shortly for heavier loads. Luckily, unlike certain hardware (looking at you Apple), it is easy to fix. All it needs is a new battery. So I found that [[https://www.ifixit.com/Guide][ifixit]] had the right parts and a *very* useful kit with all the right tools to do the job.

It only took 10 minutes to do, and now my trusty old laptop is able to last 7 to 8 hours again! Gotta love the ability to repair things. I hope it lasts another 5 to 6 years!

* DONE Advent of Code 2024 :@writing:
CLOSED: [2024-12-10 di] 
:PROPERTIES:
:EXPORT_FILE_NAME: aoc-2024
:END:

It is December again and that means it is time for the [[https://adventofcode.com/][Advent of Code]]. Due to my workload and family obligations I will probably not be able to get very far this year, but still I wanted to write a post about it.

This year I am using Java, together with my students. My goal is to write as modern as possible Java, which means using streams and new language constructs where possible.

** Day 1

In day 1 we are parsing 2 lists of numbers, with the lists printed vertically. This means each line has 2 numbers, one for list one and the other for list two. To parse these data structures I used a very nice stream where I ~map~ each line onto a ~String[]~ using ~split~.

To be sure that the input is valid, the ~peek~ method allows you to check if the result is what you intended, and otherwise an exception will terminate everything. From here I ~map~ the ~String[]~ into a ~Pair~ record which holds the 2 numbers. Streaming over the resulting ~pairs~ the left and right lists can be extracted quite easily.

I loved this approach, it is very straightforward and does not have a lot of control flow.

#+begin_src java
@Override
public List<List<Integer>> parseInput(List<String> input) {
    var pairs = input.stream()
        .map(s -> s.split("\\s+"))
        .peek(parts -> {
                if (parts.length != 2)
                    throw new IllegalArgumentException("Invalid input format");
            })
        .map(parts -> new Pair<>(Integer.parseInt(parts[0]), Integer.parseInt(parts[1])))
        .collect(Collectors.toList());

    var left = pairs.stream()
        .map(Pair::left)
        .collect(Collectors.toList());

    var right = pairs.stream()
        .map(Pair::right)
        .collect(Collectors.toList());

    return List.of(left, right);
}
#+end_src

Solving the problem with these lists was quite easy. In part 2 there was a need for a frequency table of a list. I also found a very nice solution to that problem using the ~groupingBy~ method from ~Collectors~.

#+begin_src java
input.get(1).stream()
    .collect(Collectors.groupingBy(n -> n, Collectors.counting()));
#+end_src

** Day 2

I really liked day 2, the first part was quite straightforward. You have to identify increment or decrement only lists and apply some conditions to them.

Part 2 was much more interesting, here you have to account for fault tolerance. In the Python implementations that were posted the common solution is to concatenate 2 parts of the array and then rerun the validation logic.

Using streams we can something very similar. First we use an ~IntStream~ to iterate over every ~int[]~ (report). Then for every ~int~ in that report, we construct a new array by ~filtering~ out the index of the current item. After that it is a simple case of determining increment or decrement and applying the conditional logic.

#+begin_quote
Suppose you have a list of ~[1,2,4,7]~, while iterating it will first hit index ~0~, the ~filter~ will prevent that entry from continuing. Next ~1~ through ~3~ will continue and as a result of ~toArray()~ a new array will be constructed with only those items.
#+end_quote

#+begin_example
x == 0
     |    map ------.
     v  -------     v
    [1, 2, 4, 7]    [2,4,7]
#+end_example


#+begin_src java
input.stream()                                  
    // Loop over the list
    .filter(in -> IntStream.range(0, in.length) // take a report
            // for every entry in that int[]
            .anyMatch(x -> {
                    // create a new list, excluding the one we are on now
                    int[] c = IntStream.range(0, in.length)
                        .filter(i -> i != x)
                        .map(i -> in[i])
                        .toArray();

                    boolean allInc = IntStream.range(0, c.length - 1)
                        .allMatch(i -> c[i] <= c[i + 1]);

                    boolean allDec = IntStream.range(0, c.length - 1)
                        .allMatch(i -> c[i] >= c[i + 1]);

                    boolean good = IntStream.range(0, c.length - 1)
                        .allMatch(i -> Math.abs(c[i] - c[i + 1]) >= 1 &&
                                  Math.abs(c[i] - c[i + 1]) <= 3);

                    // matching the condition
                    return (allInc || allDec) && good;
                })
            )
    .count();
#+end_src

My first solution was nothing like this, but after refining it I am very happy with how clean it came out.

** Day 3

This was the traditional easy puzzle after a more complicated one. Basically simple parsing for which I used regular expressions. Nothing special, on to day 4.

** Day 4

For day 4 I solved the first part with an over engineered path finding solution, which turned out to be quite the overkill, but extremely fun to program.

I really like the pattern in use, below is some of the code of it. First you create a ~Deque~ that holds the work, then you load it up with the initial starting points. In the case of the puzzle these are the location of the ~X~ characters.

From there you just loop over the ~work~, taking a partial solution and seeing if any cells around it will lead to another partial solution, so from ~XM~ to ~XMA~ and on the next iteration to ~XMAS~. The ~dx~ is a collection of ~Coord~ that indicate valid movements across the board.

#+begin_src java
Deque<Path> work = new ArrayDeque<>();

// Load initial points
for (int y = 0; y < input.length; y++) {
    for (int x = 0; x < input[y].length; x++) {
        if (input[y][x] == 'X') {
            work.add( new Path(List.of(new Coord(x,y)), "X", null) );
        }
    }
}

// Process each outstanding point..
while (!work.isEmpty()) {
    var path = work.pop();
    for (Coord d : dx) {
        if (path.dir() != null && path.dir != d) {
            continue;
        }
        var newCoord = lastStep.add(d);
        // Ensure this is a valid point on the grid
        if (newCoord.x() >= 0 && newCoord.x() < input[0].length &&
            newCoord.y() >= 0 && newCoord.y() < input.length) {
            // ... create new paths and string based on location
            // Check if we have an end case, else add it to the work
            if (target.equals(xmas)) {
                matches.add(newPath);
            } else if (target.startsWith(xmas)) {
                work.add(newPath);
            }

        }
    }
}
#+end_src

A more straightforward approach, which was actually needed for part 2, is to just try to solve it in one step. First you iterate over both ~y~ and ~x~ coordinates looking for an ~X~, just as above. When you find one, iterate over ~[-1, 0, 1]~ on both the ~x~ and ~y~ axis-es, using ~dy~ and ~dx~ for the *direction*. If both ~direction~ are ~0~, we continue as it would give the current position. The beauty of this approach is that you can move outward in steps, ~x + 3 * dx~ will give you a value 3 cells in the give ~direction~. From there it is a simple matter of checking if we are in bounds and if the letters spell *MAS*.

#+begin_src java
for (int y = 0; y < input.length; y++) {
    for (int x = 0; x < input[y].length; x++) {
        if (input[y][x] != 'X') continue;
        for (int dy = -1; dy <= 1; dy++) {
            for (int dx = -1; dx <= 1; dx++) {
                if (dy == dx && dx == 0) continue;
                if (!(0 <= y + 3 * dy && y + 3 * dy < input.length &&
                      0 <= x + 3 * dx && x + 3 * dx < input[y].length)) continue;

                if (input[y+1*dy][x+1*dx] == 'M' &&
                    input[y+2*dy][x+2*dx] == 'A' &&
                    input[y+3*dy][x+3*dx] == 'S') {
                    matches++;
                }
            } 
        }
    }
}
#+end_src

For part 2 a similar approach can be used, however the order is not important. So I chose to create a ~List~ and then check against a target list with the ~containsAll~ method, it does not care about order.

#+begin_src java
var x1 = List.of(input[y-1][x-1], input[y][x], input[y+1][x+1]);
var x2 = List.of(input[y-1][x+1], input[y][x], input[y+1][x-1]);
if (x1.containsAll( target ) && x2.containsAll( target )){
    matches++;
}
#+end_src

Another reminder to not over engineer at the start.


** Day 5

Another fun puzzle, when I initially read it my mind jumped to graphs. There is a 2 part input, the first part being a list of rules, numbers that are only valid when they are placed in front of other numbers.

The second part of the input is a list of ~report~ structures. The first quest was to validate the reports and find only the valid ones.

My first attempt, in part 1, was to take the rules for a number (a ~List<Integer>~) and see if there is an ~anyMatch~ of the sublist before it using ~order::contains~. Basically if the pages is ~75,97,47,61,53~ and the rule ~97|75~ (97 should be before 75), the the loop will iterate over the pages, and check to see if ~[75]~ is in the list of rules for ~97~.

#+begin_src java
boolean isValid(List<Integer> pages, Instructions input) {
    var valid = true;
    for (int i = 0; i < pages.size(); i++) {
        var order = input.order().get(pages.get(i));
        if (order != null) {
            var hasAny = pages.subList(0,i+1).stream().anyMatch(order::contains);

            if (hasAny) {
                valid = false;
            }
        }
    }
    return valid;
}
#+end_src

Part 2 had us fixing the broken pages. After some initial magic with arrays I figured out it is a basic sorting problem. In Java you can use ~Comparator~ implementations to create custom sorting rules, as long as it responds with ~-1,0,1~ for to the left, the same, to the right. So the lambda ~Comparator~ takes a left hand side and right hand side value, retrieves the rules for the left hand side (if ~null~ it is equal ~0~) and checks to see if the right hand side is in the ruleset (~-1~). If all checks fail, the value should go to the right hand side.

#+begin_src java
var answer = 0L;
for (var pages : input.pages()) {
    var valid = isValid(pages, input);
    var work = new ArrayList<>(pages); // pages is immutable
    if (!valid) {
        Collections.sort(work, (lhs, rhs) -> {
                var order = input.order().get(lhs);
                if (order == null) return 0;
                if (order.contains(rhs)) return -1;
                return 1;
            });
        answer += work.get(work.size()/2); 
    } 
}
#+end_src

A surprisingly easy solution to a messy problem when you want to implement it yourself.

** Day 6

Traditionally the Friday puzzles seem to be somewhat more challenging, this Friday is no exception. We are given a challenge similar to sliding puzzle games.

#+HTML:<video autoplay loop muted><source src="/ox-hugo/sliding.mp4"></video>

Instead of sliding over ice we are to map the movements of a guard to ensure we can move safely through the area. For part 1 there was nothing too exciting, just move the guard over the floor and track the places visited. Depending on your loop you might accidentally avoid an edgecase that will show up in part 2.

Lets take a look at the loop:

#+begin_src java
while (inBounds) {
    visited.add(start);
    var next = start.add(delta.get(sign));
    if (!next.inBound(0, input[0].length, 0, input.length)) {
        inBounds = false;
        continue;
    }
    if (input[next.y()][next.x()] == '#') {
        sign = turns.get(sign);
        continue;
    }
    start = next;
}
#+end_src

While we are **in bounds** we keep moving, adding each step into the ~visited~ list. We then get the next position by retrieving the delta (a lookup table of coordinates such as ~-1,0~, which indicate that the guard will move ~-1~ on the x-axis and ~0~ on the y-axis). If we are out of bounds, flip the switch and break out of the ~while~ loop, if the ~next~ position is an obstacle, ~#~, we set the ~sign~ to the 90 degree turned version (another lookup table) and rerun the loop. If, for some reason, you continue checking and validating at this point you might miss the edge-case that turning can result in facing another wall. When all the conditions are checked, simply reset the ~start~ variable to the next coordinates and move on.

Part 2 becomes much more interesting; we are to find infinite loops by placing exactly 1 extra obstacle. Intuitively you will remark that the obstacle can only be placed on one of the cells that were visited in part 1. This already eliminates part of the board. From here you can loop over the list of coordinates, place an obstacle and let the guard run its route. When you visit a coordinate twice in **the same direction** you know you are in a loop.

I looked for a "smart" solution, but the brute force is done in less then 2 seconds. So I will leave it at this, but somehow feel there might be more optimizations possible.

** Day 7

The end of week 1, and easier then the Friday puzzle. We are given a list of numbers per line that we need to either /add/ or /multiply/ to get to a target number. I chose to use some recursion to solve this problem. Each iteration of the recursion will reduce the array of numbers using one of the operations.

In the end the list of numbers will be reduced to either the target number, or something else. So the base case checks to see if it was successful.

If the base case is not hit, the first recursion is to add the numbers. A trick here is to use a ~LongStream~ to range over ~1~ to the end, mapping the numbers. If number ~1~ is mapped, we add the number at position ~0~ to reduce the array.

The second case applies the multiplication in the same way.

The third case (part 2) is to concatenate the numbers, this is easil done through ~number + "" + number~ in java, coercing the numbers into a ~String~ and then using ~Long.valueOf()~ to read the value again.

#+begin_src java
boolean isValid(long target, long[] numbers, boolean third) {
    if (numbers.length == 1) return target == numbers[0];
    if (isValid(target, LongStream.range(1, numbers.length)
                .map(i -> {
                        if (i == 1) return numbers[0] + numbers[1];
                        return numbers[(int)i];
                    })
                .toArray(), third)) return true;
    if (isValid(target, LongStream.range(1, numbers.length)
                .map(i -> {
                        if (i == 1) return numbers[0] * numbers[1];
                        return numbers[(int)i];
                    })
                .toArray(), third)) return true;
    if (third && isValid(target, LongStream.range(1, numbers.length)
                          .map(i -> {
                                  if (i == 1) return Long.valueOf(numbers[0] + "" + numbers[1]);
                                  return numbers[(int)i];
                              })
                          .toArray(), third)) return true;
    return false;
}
#+end_src

One last trick is to use the ~Stream~ feature to ~filter~ the list, mapping each object to a long value and summing.

#+begin_src java
@Override public Long solver1(List<Calibration> input) {
    return input.stream().filter(i -> isValid(i.target, i.numbers, false)).mapToLong(cal -> cal.target).sum();
}
#+end_src

** Day 8

Day 8 has us back in history staring at antennas. The description was quite cryptic, but reading it carefully you learn that the necessary step is to find the difference between a pair of coordinates and then extrapolate the path inside the bounds of the grid.

To read the grid into a structure I used a simple nested loop, adding a new list to the map if it is absent, then adding the new coordinate for the antenna.

#+begin_src java
for (int r = 0; r < gridH; r++) {
    for (int c = 0; c < gridW; c++) {
        char ch = input.get(r).charAt(c);
        if (ch != '.') {
            antennas.computeIfAbsent(ch, k -> new ArrayList<>()).add(new Coord(c, r));
        }
    }
}
#+end_src

We then have to find the ~antinode~ for the point which, for the pair, is just a single difference step from the antenna. Interestingly we need to count the **unique** antinodes. Whenever you get such a requirement, always think about using a ~Set~ for storage.

Getting the pairs is straightforward, and we have done it earlier in the series already. The first loop starts at ~0~ and ends the element before the end, ~size - 1~. The inner loop starts at ~current pos + 1~ and ends at the size of the list.

#+begin_src java
for (int p = 0; p < coords.size() - 1; p++) {
    for (int n = p + 1; n < coords.size(); n++) {
#+end_src

Then just compute the difference and add the antinode when it is in bounds.

#+begin_src java
var antinode1 = cur.add(cur.diff(next));
var antinode2 = next.add(next.diff(cur));
#+end_src

In part 2 the path needs to be extrapolated until it goes out of bounds. This can easily be wrapped in its own method.

#+begin_src java
void addAntinodesInDirection(Set<Coord> antinodes, Coord start, Coord diff) {
    var current = start;
    while (true) {
        var next = current.add(diff);
        if (!next.inBound(0, gridW, 0, gridH)) {
            break;
        }
        antinodes.add(next);
        current = next;
    }
}
#+end_src

A pretty straightforward problem to solve, on to tomorrow!

** Day 9

For me this was a hard day. We are given a list of numbers that we use to fragment files on a disk. The first part of the puzzle was quite straightforward, create a list that holds the file ids and spaces and just follow the rules.

#+begin_src java
for (int i = 0; i < input.length(); i++) {
    for (int j = 0; j < input.charAt(i)-'0'; j++) {
        if (i%2 == 0) {
            disk.add(id);
        } else {
            disk.add(null);
        }
    }
    if (i%2 == 0) {
        id++;
    }
}
#+end_src

From there just create 2 pointers, one on the left and one on the right. The left tracks the empty space and the right tracks the file ids that we want to put in the empty space. The important thing in Java is to make the implementation of the list a ~LinkedList~. This allows for little-overhead reshuffling of the list.

#+begin_src java
var l = 0;
var r = disk.size() - 1;
while (l < r) {
    if (disk.get(l) != null) {
        l++;
        continue;
    }

    if (disk.get(r) == null) {
        r--;
        continue;
    }

    disk.set(l, disk.get(r));
    disk.set(r, null);
    l++;
    r--;
}
#+end_src

Part 2 became much harder, we are not to find space for the blocks of files instead of fragments. I first tried the same approach, but it took forever. I then saw the error of my ways and decided to use a lookup table for the empty spaces. This table maps the empty spaces of size ~N~, in the below example 1 and 2, to a list of start/end coordinates.

#+begin_example
1 = [1,1] [2,2]
2 = [3,4] [6,7]
#+end_example

The list of coordinates needs to remain sorted, so I used a ~PriorityQueue~ for it. Then it is just a matter of determining the size of the file under the ~r~ pointer by looping over it until we hit another id, and then looking up the most left candidate of the empty spaces.

#+begin_src java
// Gets all candidates that will fit the file
for (int i = bs; i < 10; i++) {
    var earliest = free[i].peek();
    if (earliest != null && earliest < r) {
        candidates.add(new Candidate(i, earliest));
    }
}

if (candidates.isEmpty()) {
    return null;
}

// Sort based on the index (most left first)
candidates.sort((lhs, rhs) -> {
    return lhs.idx() - rhs.idx();
});

var can = candidates.getFirst();
free[can.size()].remove();
#+end_src

The final solution runs in a matter of milliseconds, so I am quite happy with that.

** Day 10

Finally a depth first / breath first path seeker! We need to identify a trail that leads to a summit, or rather all trails that lead to the summit. Part 1 wants to know the score (how many summits can a path reach) and part 2 its rating (how many trails are there that reach a summit). This is pretty straightforward in the sense that you create a ~Queue~ and put the start of the trail in, then for each direction you construct a more complete path.

As always it is important to check for bounds and if the path is incremental (business rule). If the new path is actually at the summit, add it to the finished paths. If it is not, try to complete it.

#+begin_src java
Trail solve(char[][] grid, Coord zero) {
var q = new ArrayDeque<List<Coord>>();
q.add(List.of(zero));

List<List<Coord>> paths = new ArrayList<>();
while (!q.isEmpty()) {
    var current = q.removeFirst();

    for (Coord d : zero.directNeighbors()) {
        var last = current.getLast();
        var nc = last.add(d);

        if (!nc.inBound(0,grid[0].length, 0, grid.length)) continue;
        if (grid[nc.y()][nc.x()] != grid[last.y()][last.x()] + 1) continue;

        var newPath = new ArrayList<>(current);
        newPath.add(nc);

        if (grid[nc.y()][nc.x()] == '9') {
            paths.add(newPath);
        } else {
            q.addLast(newPath);
        }

    }
}
var score = paths.stream().map(l->l.getLast()).collect(Collectors.toSet()).size();
var rating = paths.size();

return new Trail(score, rating);
#+end_src

** More to come

[This article will be update with more days]
