<!doctype html>
<html
  lang="en-us"
  dir="ltr"
>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8" />
<meta name="language" content="en" />
<meta name="viewport" content="width=device-width" />
<title>
    The Dutch are WEIRD, and so is ChatGPT | Arjen Wiersma
</title>
  <meta name="description" content="Series note In this post I explore a new paper in my series of Research Driven Blogs . I’m Dutch, and whenever I’m abroad, people figure this out pretty quickly. It’s usually the bluntness. We tend to be direct, to the point, and question things constantly. To a lot of people, this comes across as… well, weird.
That word, “weird”, has been on my mind a lot lately, especially when I hear the LLM providers tell us that Large Language Models (LLMs) have achieved “human-level performance." />
<meta property="og:url" content="http://localhost:1313/posts/20251024-weird-llm/">
  <meta property="og:site_name" content="Arjen Wiersma">
  <meta property="og:title" content="The Dutch are WEIRD, and so is ChatGPT">
  <meta property="og:description" content="Series note In this post I explore a new paper in my series of Research Driven Blogs . I’m Dutch, and whenever I’m abroad, people figure this out pretty quickly. It’s usually the bluntness. We tend to be direct, to the point, and question things constantly. To a lot of people, this comes across as… well, weird.
That word, “weird”, has been on my mind a lot lately, especially when I hear the LLM providers tell us that Large Language Models (LLMs) have achieved “human-level performance.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-10-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-10-24T00:00:00+00:00">


  <meta itemprop="name" content="The Dutch are WEIRD, and so is ChatGPT">
  <meta itemprop="description" content="Series note In this post I explore a new paper in my series of Research Driven Blogs . I’m Dutch, and whenever I’m abroad, people figure this out pretty quickly. It’s usually the bluntness. We tend to be direct, to the point, and question things constantly. To a lot of people, this comes across as… well, weird.
That word, “weird”, has been on my mind a lot lately, especially when I hear the LLM providers tell us that Large Language Models (LLMs) have achieved “human-level performance.">
  <meta itemprop="datePublished" content="2025-10-24T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-10-24T00:00:00+00:00">
  <meta itemprop="wordCount" content="1316">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="The Dutch are WEIRD, and so is ChatGPT">
  <meta name="twitter:description" content="Series note In this post I explore a new paper in my series of Research Driven Blogs . I’m Dutch, and whenever I’m abroad, people figure this out pretty quickly. It’s usually the bluntness. We tend to be direct, to the point, and question things constantly. To a lot of people, this comes across as… well, weird.
That word, “weird”, has been on my mind a lot lately, especially when I hear the LLM providers tell us that Large Language Models (LLMs) have achieved “human-level performance.">

<link rel="canonical" href="http://localhost:1313/posts/20251024-weird-llm/" />

    <link rel="stylesheet" href="/css/index.css" />


      <script src="/js/main.js" defer></script>
  
  



<script type="application/ld+json">
{
  "@context": "https://schema.org/",
  "@id": "http://localhost:1313/posts/20251024-weird-llm/",
  "@type": "BlogPosting",
  "author": {
    "@type": "Person",
    "name": "Arjen Wiersma"
  },
  "copyrightNotice": "Arjen Wiersma",
  "datePublished": "2025-10-24",
  "description": "Series note In this post I explore a new paper in my series of Research Driven Blogs . I’m Dutch, and whenever I’m abroad, people figure this out pretty quickly. It’s usually the bluntness. We tend to be direct, to the point, and question things constantly. To a lot of people, this comes across as… well, weird.\nThat word, “weird”, has been on my mind a lot lately, especially when I hear the LLM providers tell us that Large Language Models (LLMs) have achieved “human-level performance.",
  "headline": "The Dutch Are WEIRD, and So Is ChatGPT",
  "isPartOf": {
    "@id": "http://localhost:1313/posts/",
    "@type": "Blog",
    "name": "Posts"
  },
  "mainEntityOfPage": "http://localhost:1313/posts/20251024-weird-llm/",
  "name": "The Dutch Are WEIRD, and So Is ChatGPT",
  "timeRequired": "PT7M",
  "url": "http://localhost:1313/posts/20251024-weird-llm/",
  "wordCount": 1316
}
</script>


  </head>
  <body>
    <div class="container mx-auto flex max-w-prose flex-col space-y-10 p-4 md:p-6">
      <header class="flex flex-row items-center justify-between">
        <div>
  <a id="skip-nav" class="sr-only" href="#maincontent">Skip to main content</a>
  <a class="font-semibold" href="/">Arjen Wiersma</a>
</div>

  <nav>
    <ul class="flex flex-row items-center justify-end space-x-4">
    <li>
      <a href="/talks/">Talks</a
      >
    </li>
    <li>
      <a href="/notes/">Notes</a
      >
    </li>
    <li>
      <a aria-current="true" class="ancestor" href="/posts/">Posts</a
      >
    </li>
    <li>
      <a href="/graph/">Graph</a
      >
    </li>
    </ul>
  </nav>


      </header>
      <main class="prose prose-slate relative md:prose-lg prose-h1:text-[2em]" id="maincontent">
        <article class="main">
    <header>
      <h1 class="!mb-1">The Dutch Are WEIRD, and So Is ChatGPT</h1><div class="flex flex-row items-center space-x-4">
          <time class="text-sm italic opacity-80" datetime="2025-10-24T00:00:00&#43;00:00"
            >October 24, 2025</time
          >
        </div>
    </header>

    <figure
  role="note"
  id="admonition-00"
  aria-labelledby="admonition-caption-00"
  class="admonition tip  not-prose"
>
  <div class="flex items-center space-x-2 pb-2 font-semibold">
      <svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-flame block"
>
  <path
    d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"
  />
</svg>

    <figcaption id="admonition-caption-00">
        Series note
    </figcaption>
  </div>

  <div class="prose pl-8 text-inherit marker:text-inherit">
    In this post I explore a new <a href="https://scholar.harvard.edu/sites/scholar.harvard.edu/files/henrich/files/which_humans_09222023.pdf">paper</a> in my series of <!-- raw HTML omitted -->Research Driven Blogs<!-- raw HTML omitted -->
.
  </div>
</figure>

<p>I&rsquo;m Dutch, and whenever I&rsquo;m abroad, people figure this out pretty quickly. It&rsquo;s usually the bluntness. We tend to be direct, to the point, and question things constantly. To a lot of people, this comes across as&hellip; well, weird.</p>
<p>That word, &ldquo;weird&rdquo;, has been on my mind a lot lately, especially when I hear the LLM providers tell us that Large Language Models (LLMs) have achieved &ldquo;human-level performance.&rdquo; I’ve been in tech and security for a long time, and I’ve seen more &ldquo;revolutions&rdquo; than I can count, but the chatter about this one is everywhere. Each model is more human then the last one it seems.</p>
<p>It&rsquo;s an impressive claim, and the demos are slick. But in our line of work, we&rsquo;re paid to be paranoid. We&rsquo;re trained to ask the follow-up questions, the ones that spoil the party. When I hear &ldquo;human-level performance,&rdquo; one question comes to mind: <strong>&ldquo;Which humans?&rdquo;</strong></p>
<p>It’s not a trick question. We&rsquo;re a weirdly diverse species. A rice farmer in rural China, a herder in the Maasai Mara, and a philosophy student in Stockholm don&rsquo;t just have different opinions; their brains are wired to process information in fundamentally different ways. Trust, morality, logic, even how they see <em>themselves</em>&hellip; it&rsquo;s all variable.</p>
<p>The problem is, these LLMs aren&rsquo;t being trained on that full spectrum of diversity. They&rsquo;re being trained on data from one very specific, and globally unusual, sliver of humanity. That sliver is what researchers call <strong>WEIRD</strong>: Western, <span class="sidenote">
  <input
    aria-label="Show sidenote"
    type="checkbox"
    id="sidenote-checkbox-02"
    class="sidenote-checkbox hidden"
  />
  <label
    tabindex="0"
    role="mark"
    aria-details="sidenote-02"
    for="sidenote-checkbox-02"
    class="sidenote-mark"
    >Educated</label
  >
  <small id="sidenote-02" class="sidenote-content">
    <span class="sr-only"> (sidenote: </span>Even though some politicians think it a good idea to destroy our educational system<span class="sr-only">)</span>
  </small>
</span>
, Industrialized, Rich, and Democratic.</p>
<p>If you&rsquo;re reading this, you are almost certainly part of that group. And so, it turns out, is ChatGPT.</p>
<h3 id="the-weird-in-weird-out-problem" class="scroll-mt-8 group">
  The &ldquo;WEIRD in, WEIRD out&rdquo; problem
  
    <a href="#the-weird-in-weird-out-problem"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>In security, we have a foundational concept: &ldquo;Garbage In, Garbage Out.&rdquo; A system is only as good as the data you feed it. A model trained on junk will give you junk. AI is no different.</p>
<p>So, how did our supposedly &ldquo;global&rdquo; AI models end up with one very specific psychological profile? They were trained on the internet. And the internet is not a mirror of humanity; it’s a funhouse mirror that reflects its most active users.</p>
<ol>
<li>
<p><strong>Access:</strong> Nearly half the world’s population isn&rsquo;t even online. The data we&rsquo;re scraping is missing <em>billions</em> of perspectives from the start. That&rsquo;s not a rounding error; it&rsquo;s a colossal blind spot.</p>
</li>
<li>
<p><strong>Language:</strong> The training data is overwhelmingly, colossally dominated by English. This isn&rsquo;t just a language issue; it&rsquo;s a cultural one. English-speaking populations are, by definition, a psychological outlier on the global stage.</p>
</li>
</ol>
<p>The AI, in its quest to find patterns, is just learning the patterns of its most over-represented users. It&rsquo;s not just &ldquo;Garbage In, Garbage Out.&rdquo; It&rsquo;s <strong>&ldquo;WEIRD In, WEIRD Out.&rdquo;</strong> The model is faithfully replicating the psychological skew of its training data.</p>
<h4 id="the-evidence-how-to-build-a-digital-dutchman" class="scroll-mt-8 group">
  The evidence: how to build a digital Dutchman
  
    <a href="#the-evidence-how-to-build-a-digital-dutchman"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>The researchers didn&rsquo;t just guess this; they tested it. They gave ChatGPT a battery of classic cross-cultural psychology tests and compared its answers to a massive dataset from 65 nations. The results are quite astounding.</p>
<p><strong>Test 1: The &ldquo;Cultural Map&rdquo;</strong>
First, they used the World Values Survey—a huge dataset on global attitudes about morality, politics, and trust. They mapped all 65 nations and ChatGPT to see who &ldquo;clustered&rdquo; with whom.</p>
<p>ChatGPT didn&rsquo;t land in some neutral &ldquo;robot space.&rdquo; It landed smack in the middle of the WEIRD cluster. Its closest psychological neighbors? The United States, Canada, Great Britain, Australia&hellip; and, of course, <strong>The Netherlands</strong>.</p>
<p>The correlation was stark: the <em>less</em> WEIRD a country&rsquo;s culture was, the <em>less</em> its people&rsquo;s values resembled ChatGPT&rsquo;s.</p>
<p><strong>Test 2: The &ldquo;Shampoo, Hair, Beard&rdquo; Test</strong>
This is the one that really got me. In a classic &ldquo;triad task,&rdquo; you&rsquo;re given three words and asked to pair the two that are most related. For example: &ldquo;shampoo,&rdquo; &ldquo;hair,&rdquo; and &ldquo;beard.&rdquo;</p>
<p>The difference in thinking is stark. A <strong>holistic thinker</strong>, common in less-WEIRD societies, tends to pair &ldquo;shampoo&rdquo; and &ldquo;hair&rdquo; because they have a <em>functional relationship</em> (you use one on the other). In contrast, an <strong>analytic thinker</strong>, common in WEIRD societies, pairs &ldquo;hair&rdquo; and &ldquo;beard&rdquo; because they belong to the same <em>abstract category</em> (they are both types of hair).</p>
<p>When they ran this test on GPT 1,100 times, the results were stunning. On the graph of all human populations, GPT’s percentage of analytic, WEIRD-style choices was <strong>almost identical</strong> to that of the Netherlands. They are plotted as next-door neighbors at the very top of the analytic-thinking chart.</p>
<p>It doesn&rsquo;t just <em>agree</em> with the Dutch; it <em>thinks</em> like them.</p>
<p><img src="/images/which_humans.png" alt="Human vs LLM analytical thinking"></p>
<p><strong>Test 3: The &ldquo;Who Am I?&rdquo; Test</strong>
This bias isn&rsquo;t just about values or logic; it&rsquo;s about a fundamental sense of self. Psychologists have a simple test: ask someone to complete the sentence &ldquo;I am&hellip;&rdquo; ten times.</p>
<p>The responses to this test show a clear cultural divide. WEIRD people overwhelmingly list personal attributes: &ldquo;I am smart,&rdquo; &ldquo;I am an athlete,&rdquo; &ldquo;I am hardworking.&rdquo; In sharp contrast, people from less-WEIRD cultures overwhelmingly list social roles and relationships: &ldquo;I am a son,&rdquo; &ldquo;I am a member of my village,&rdquo; &ldquo;I am an employee of X company.&rdquo;</p>
<p>So, what does ChatGPT think an &ldquo;average person&rdquo; is? You guessed it. When asked, it generated a list of personal characteristics, mirroring the self-concept of US undergrads. It perceives the &ldquo;average human&rdquo; through a WEIRD lens, completely missing the relational self-concept that is the norm for <em>most</em> of the planet.</p>
<h3 id="why-this-matters" class="scroll-mt-8 group">
  Why this matters
  
    <a href="#why-this-matters"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>Okay, so the AI is a bit weird. Why should we, as tech professionals, care? Because in our field, a system with a built-in, predictable blind spot isn&rsquo;t a curiosity, it&rsquo;s a <strong>liability</strong>.</p>
<p>We&rsquo;re in the business of risk. We are rushing to integrate these models into every layer of our stack. They&rsquo;re not just toys anymore. They&rsquo;re in our code review pipelines, our content moderation filters, and our HR software that screens resumes.</p>
<p>Now, picture that &ldquo;Digital Dutchman&rdquo; logic applied at scale. A <strong>content moderation</strong> filter trained on WEIRD norms of &ldquo;harm&rdquo; will be systematically blind to what&rsquo;s considered offensive or dangerous in other cultures, while over-policing things it finds &ldquo;bizarre.&rdquo; An <strong>HR tool</strong> built on WEIRD ideas of self-promotion (&ldquo;I am smart&rdquo;) might filter out perfectly qualified candidates from cultures where boasting is a taboo and group-contribution is the norm (&ldquo;We achieved&hellip;&rdquo;). And a <strong>code-assist</strong> AI, when asked for &ldquo;simple&rdquo; or &ldquo;logical&rdquo; code, will default to an analytic, WEIRD-style structure. Is that always the right, most robust, or most secure solution? Or just the one that <em>feels</em> right to its internal psychologist?</p>
<p>This isn&rsquo;t a hypothetical problem. The researchers noted this bias persists even in multilingual models [1]. You can&rsquo;t just &ldquo;translate&rdquo; your way out of a core psychological skew. What we have here is a systemic vulnerability.</p>
<h3 id="we-didnt-build-a-human-ai-we-built-a-weird-one" class="scroll-mt-8 group">
  We didn&rsquo;t build a &ldquo;Human&rdquo; AI, we built a WEIRD one.
  
    <a href="#we-didnt-build-a-human-ai-we-built-a-weird-one"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>The takeaway here isn&rsquo;t that LLMs are useless. It&rsquo;s that we have to be ruthlessly realistic about what they are. This isn&rsquo;t a step toward &ldquo;artificial general intelligence.&rdquo; This is an echo chamber.</p>
<p>These models aren&rsquo;t &ldquo;human-like.&rdquo; They are <em>a</em>-human-like. They&rsquo;re stochastic parrots that have been trained on a very specific, psychologically peculiar dataset.</p>
<p>A tool that is fundamentally blind to the perspectives of most of the planet isn&rsquo;t &ldquo;objective.&rdquo; It&rsquo;s a system with a massive, built-in bias. And as we race to embed this system into the foundations of our global society, we&rsquo;re not building a universal brain; we&rsquo;re exporting a single, peculiar psychology.</p>
<p>And for those of us in the security field, a system with a blind spot that big&hellip; well, that’s what we call job security.</p>
<p>Find more <a href="/notes/research-driven-blogs/" class="backlink">Research Driven Blogs</a>
.</p>
<h3 id="bibliography" class="scroll-mt-8 group">
  Bibliography
  
    <a href="#bibliography"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<ol>
<li>Atari, M., Xue, M. J., Park, P. S., Blasi, D. E., &amp; Henrich, J. (2023). <em>Which Humans?</em> (Unpublished manuscript). Department of Human Evolutionary Biology, Harvard University.</li>
</ol>

  </article>
    <aside class="not-prose flex flex-col space-y-8 border-t pt-6">
    <section class="flex flex-col space-y-4" aria-hidden="true">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-chart-network h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="m13.11 7.664 1.78 2.672M14.162 12.788l-3.324 1.424M20 4l-6.06 1.515M3 3v16a2 2 0 0 0 2 2h16"
  />
  <circle cx="12" cy="6" r="2" />
  <circle cx="16" cy="12" r="2" />
  <circle cx="9" cy="15" r="2" />
</svg>

        <span>Graph</span>
      </h2>

      <content-network-graph
  class="h-64 ml-6"
  data-endpoint="/graph/index.json"
  page="/posts/20251024-weird-llm/"
></content-network-graph>

    </section>
    <section class="flex flex-col space-y-4">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-notebook-text h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path d="M2 6h4M2 10h4M2 14h4M2 18h4" />
  <rect width="16" height="20" x="4" y="2" rx="2" />
  <path d="M9.5 8h5M9.5 12H16M9.5 16H14" />
</svg>

        <span>Notes</span>
      </h2>
        <section class="flex flex-col space-y-1">
          <h3 class="flex flex-row items-center space-x-2 text-sm font-semibold">
            <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-arrow-up-from-dot h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path d="m5 9 7-7 7 7M12 16V2" />
  <circle cx="12" cy="21" r="1" />
</svg>

            <span>Outgoing</span>
          </h3>

          <ol class="not-prose ml-6">
    <li>
      <article class="flex flex-row items-center">
        <header class="grow">
          <h3>
            <a
              href="/notes/research-driven-blogs/"
              class="truncate text-sm underline decoration-slate-300 decoration-2 underline-offset-4 hover:decoration-inherit"
              title="Research Driven Blogs"
              >Research Driven Blogs</a
            >
          </h3>
        </header>
          <ul class="flex flex-row items-center justify-end space-x-2">
              <li>
                <a
                  href="/categories/writing/"
                  class="taxonomy"
                  title="Posts and notes on Writing"
                  >Writing</a
                >
              </li>
          </ul>
      </article>
    </li>
    <li>
      <article class="flex flex-row items-center">
        <header class="grow">
          <h3>
            <a
              href="/notes/research-driven-blogs/"
              class="truncate text-sm underline decoration-slate-300 decoration-2 underline-offset-4 hover:decoration-inherit"
              title="Research Driven Blogs"
              >Research Driven Blogs</a
            >
          </h3>
        </header>
          <ul class="flex flex-row items-center justify-end space-x-2">
              <li>
                <a
                  href="/categories/writing/"
                  class="taxonomy"
                  title="Posts and notes on Writing"
                  >Writing</a
                >
              </li>
          </ul>
      </article>
    </li>
</ol>

        </section>
    </section>
</aside>


      </main>
      <footer class="mt-20 border-t border-neutral-100 pt-2 text-xs">
        <section class="items-top flex flex-row justify-between opacity-70">
  <div class="flex flex-col space-y-2">
      <p>Copyright &copy; 2025, Arjen Wiersma.</p>
      <div
        xmlns:cc="https://creativecommons.org/ns#"
        xmlns:dct="http://purl.org/dc/terms/"
        about="https://creativecommons.org"
      >
        Content is available under
        <a href="https://creativecommons.org/licenses/by-sa/4.0/" rel="license" class="inline-block" title="Creative Commons Attribution-ShareAlike 4.0 International"
          >CC BY-SA 4.0</a
        >
        unless otherwise noted.
      </div>
        <div
          class="mt-2 flex items-center space-x-2 fill-slate-400 hover:fill-slate-600 motion-safe:transition-colors"
        >
          <div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
  aria-hidden="true"
>
  <title>Creative Commons</title>
  <circle fill="transparent" cx="37.785" cy="28.501" r="28.836" />
  <path
    d="M37.441-3.5c8.951 0 16.572 3.125 22.857 9.372 3.008 3.009 5.295 6.448 6.857 10.314 1.561 3.867 2.344 7.971 2.344 12.314 0 4.381-.773 8.486-2.314 12.313-1.543 3.828-3.82 7.21-6.828 10.143-3.123 3.085-6.666 5.448-10.629 7.086-3.961 1.638-8.057 2.457-12.285 2.457s-8.276-.808-12.143-2.429c-3.866-1.618-7.333-3.961-10.4-7.027-3.067-3.066-5.4-6.524-7-10.372S5.5 32.767 5.5 28.5c0-4.229.809-8.295 2.428-12.2 1.619-3.905 3.972-7.4 7.057-10.486C21.08-.394 28.565-3.5 37.441-3.5zm.116 5.772c-7.314 0-13.467 2.553-18.458 7.657-2.515 2.553-4.448 5.419-5.8 8.6a25.204 25.204 0 0 0-2.029 9.972c0 3.429.675 6.734 2.029 9.913 1.353 3.183 3.285 6.021 5.8 8.516 2.514 2.496 5.351 4.399 8.515 5.715a25.652 25.652 0 0 0 9.943 1.971c3.428 0 6.75-.665 9.973-1.999 3.219-1.335 6.121-3.257 8.713-5.771 4.99-4.876 7.484-10.99 7.484-18.344 0-3.543-.648-6.895-1.943-10.057-1.293-3.162-3.18-5.98-5.654-8.458-5.146-5.143-11.335-7.715-18.573-7.715zm-.401 20.915-4.287 2.229c-.458-.951-1.019-1.619-1.685-2-.667-.38-1.286-.571-1.858-.571-2.856 0-4.286 1.885-4.286 5.657 0 1.714.362 3.084 1.085 4.113.724 1.029 1.791 1.544 3.201 1.544 1.867 0 3.181-.915 3.944-2.743l3.942 2c-.838 1.563-2 2.791-3.486 3.686-1.484.896-3.123 1.343-4.914 1.343-2.857 0-5.163-.875-6.915-2.629-1.752-1.752-2.628-4.19-2.628-7.313 0-3.048.886-5.466 2.657-7.257 1.771-1.79 4.009-2.686 6.715-2.686 3.963-.002 6.8 1.541 8.515 4.627zm18.457 0-4.229 2.229c-.457-.951-1.02-1.619-1.686-2-.668-.38-1.307-.571-1.914-.571-2.857 0-4.287 1.885-4.287 5.657 0 1.714.363 3.084 1.086 4.113.723 1.029 1.789 1.544 3.201 1.544 1.865 0 3.18-.915 3.941-2.743l4 2c-.875 1.563-2.057 2.791-3.541 3.686a9.233 9.233 0 0 1-4.857 1.343c-2.896 0-5.209-.875-6.941-2.629-1.736-1.752-2.602-4.19-2.602-7.313 0-3.048.885-5.466 2.658-7.257 1.77-1.79 4.008-2.686 6.713-2.686 3.962-.002 6.783 1.541 8.458 4.627z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Credit must be given to the creator</title>
  <circle fill="transparent" cx="37.637" cy="28.806" r="28.276" />
  <path
    d="M37.443-3.5c8.988 0 16.57 3.085 22.742 9.257C66.393 11.967 69.5 19.548 69.5 28.5c0 8.991-3.049 16.476-9.145 22.456-6.476 6.363-14.113 9.544-22.912 9.544-8.649 0-16.153-3.144-22.514-9.43C8.644 44.784 5.5 37.262 5.5 28.5c0-8.761 3.144-16.342 9.429-22.742C21.101-.415 28.604-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.553-18.457 7.657-5.22 5.334-7.829 11.525-7.829 18.572 0 7.086 2.59 13.22 7.77 18.398 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.607 18.629-7.828 5.029-4.838 7.543-10.952 7.543-18.343 0-7.276-2.553-13.465-7.656-18.571-5.104-5.104-11.276-7.656-18.514-7.656zm8.572 18.285v13.085h-3.656v15.542h-9.944V33.643h-3.656V20.557c0-.572.2-1.057.599-1.457.401-.399.887-.6 1.457-.6h13.144c.533 0 1.01.2 1.428.6.417.4.628.886.628 1.457zm-13.087-8.228c0-3.008 1.485-4.514 4.458-4.514s4.457 1.504 4.457 4.514c0 2.971-1.486 4.457-4.457 4.457s-4.458-1.486-4.458-4.457z"
  />
</svg>
</div><div class="flex-none cursor-help"><svg
  version="1.0"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="5.5 -3.5 64 64"
  xml:space="preserve"
  class="w-5 h-5 block"
>
  <title>Adaptations must be shared under the same terms</title>
  <circle fill="transparent" cx="36.944" cy="28.631" r="29.105" />
  <path
    d="M37.443-3.5c8.951 0 16.531 3.105 22.742 9.315C66.393 11.987 69.5 19.548 69.5 28.5c0 8.954-3.049 16.457-9.145 22.514-6.437 6.324-14.076 9.486-22.912 9.486-8.649 0-16.153-3.143-22.514-9.429C8.644 44.786 5.5 37.264 5.5 28.501c0-8.723 3.144-16.285 9.429-22.685C21.138-.395 28.643-3.5 37.443-3.5zm.114 5.772c-7.276 0-13.428 2.572-18.457 7.715-5.22 5.296-7.829 11.467-7.829 18.513 0 7.125 2.59 13.257 7.77 18.4 5.181 5.182 11.352 7.771 18.514 7.771 7.123 0 13.334-2.609 18.629-7.828 5.029-4.876 7.543-10.99 7.543-18.343 0-7.313-2.553-13.485-7.656-18.513-5.067-5.145-11.239-7.715-18.514-7.715zM23.271 23.985c.609-3.924 2.189-6.962 4.742-9.114 2.552-2.152 5.656-3.228 9.314-3.228 5.027 0 9.029 1.62 12 4.856 2.971 3.238 4.457 7.391 4.457 12.457 0 4.915-1.543 9-4.627 12.256-3.088 3.256-7.086 4.886-12.002 4.886-3.619 0-6.743-1.085-9.371-3.257-2.629-2.172-4.209-5.257-4.743-9.257H31.1c.19 3.886 2.533 5.829 7.029 5.829 2.246 0 4.057-.972 5.428-2.914 1.373-1.942 2.059-4.534 2.059-7.771 0-3.391-.629-5.971-1.885-7.743-1.258-1.771-3.066-2.657-5.43-2.657-4.268 0-6.667 1.885-7.2 5.656h2.343l-6.342 6.343-6.343-6.343 2.512.001z"
  />
</svg>
</div>
        </div>

  </div>
    <div>
      <a
        href="https://github.com/michenriksen/hugo-theme-til"
        title="Today I Learned &#8212; A Hugo theme by Michael Henriksen"
        data-theme-version="0.6.0"
        >theme: til</a
      >
    </div>
</section>

      </footer>
    </div>
    
  </body>
</html>
